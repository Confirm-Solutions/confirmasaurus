{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imprint.nb_util import setup_nb\n",
    "setup_nb()\n",
    "import asyncio\n",
    "import redis\n",
    "import numpy as np\n",
    "\n",
    "import confirm.cloud.clickhouse as ch\n",
    "\n",
    "from confirm.adagrid.validation import AdaValidate\n",
    "import confirm.adagrid.adagrid as adagrid\n",
    "import imprint as ip\n",
    "from imprint.models.ztest import ZTest1D\n",
    "\n",
    "import clickhouse_connect\n",
    "clickhouse_connect.common.set_setting('autogenerate_session_id', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assignments(seed, n_tiles, n_workers, names):\n",
    "    # Randomly assign tiles to packets.\n",
    "    np.random.seed(seed)\n",
    "    splits = np.array_split(np.arange(n_tiles), n_workers)\n",
    "    assignment = np.empty(n_tiles, dtype=np.int32)\n",
    "    for i in range(n_workers):\n",
    "        assignment[splits[i]] = names[i]\n",
    "    rng = np.random.default_rng()\n",
    "    rng.shuffle(assignment)\n",
    "    return assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glossary\n",
    "\n",
    "- **coordination**: All workers come together and divide up all tiles.\n",
    "- **step**: A worker checks the convergence criterion, select tiles, and simulates.\n",
    "- **packet**: The unit of simulation work that a worker requests from the DB.\n",
    "- **batch**: The unit of simulation work that is passed to a Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:confirm.cloud.clickhouse:[worker_id=1] \n",
      "Clickhouse config: default@t2n4z83v82.us-east-1.aws.clickhouse.cloud:8443/None\n",
      "INFO:confirm.cloud.clickhouse:[worker_id=1] \n",
      "Clickhouse config: default@t2n4z83v82.us-east-1.aws.clickhouse.cloud:8443/14e0a625ccff46c68a11992f31f08558\n",
      "INFO:confirm.cloud.clickhouse:[worker_id=1] \n",
      "Connected to job 14e0a625ccff46c68a11992f31f08558\n",
      "DEBUG:imprint.grid:[worker_id=1] \n",
      "_gen_short_uuids(n=50000, worker_id=1, t=1676050756, n_bits=18, worker_bits=18) = [4496866493040164864 4496866493040164865 4496866493040164866, ...]:\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=1] \n",
      "set_or_append(config) -> False None\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=1] \n",
      "set(config) -> False config\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=1] \n",
      "writing 25000 tiles\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=1] \n",
      "set step info: (-1, 0, 0, 0)\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=1] \n",
      "set(null_hypos) -> False null_hypos\n",
      "DEBUG:confirm.adagrid.adagrid:[worker_id=1] \n",
      "first step (0, 0, 25, 25000) n_tiles=25000 packet_size=1024\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=1] \n",
      "set step info: (0, 0, 25, 25000)\n"
     ]
    }
   ],
   "source": [
    "# glossary\n",
    "\n",
    "db = ch.Clickhouse.connect()\n",
    "g = ip.cartesian_grid(\n",
    "    theta_min=[-1], theta_max=[1], n=[50000], null_hypos=[ip.hypo(\"x0 < 0\")]\n",
    ")\n",
    "kwargs = dict(\n",
    "    lam=-1.96,\n",
    "    model_seed=0,\n",
    "    model_kwargs=None,\n",
    "    delta=0.01,\n",
    "    init_K=2**13,\n",
    "    n_K_double=4,\n",
    "    tile_batch_size=64,\n",
    "    max_target=0.002,\n",
    "    global_target=0.005,\n",
    "    n_steps = 100,\n",
    "    step_size=2**10,\n",
    "    n_iter=1000,\n",
    "    packet_size = None,\n",
    "    prod = True,\n",
    "    overrides = None,\n",
    "    callback=adagrid.print_report,\n",
    "    backend=adagrid.LocalBackend(),\n",
    "    \n",
    "    model_type=ZTest1D\n",
    ")\n",
    "assignment_seed = 1\n",
    "n_workers = 2\n",
    "\n",
    "redis_con = db.redis_con\n",
    "job_id = db.job_id\n",
    "initial_worker_ids = [redis_con.incr(f\"{job_id}:worker_id\") + 1 for _ in range(n_workers)]\n",
    "\n",
    "# TODO: the assignment_seed should change with each coordination.\n",
    "g.df['worker_assignment'] = random_assignments(assignment_seed, g.n_tiles, n_workers, initial_worker_ids)\n",
    "\n",
    "packet_size = 2000\n",
    "import pandas as pd\n",
    "def assign_packets(df):\n",
    "    return pd.Series(np.floor(np.arange(df.shape[0]) / packet_size).astype(int), df.index)\n",
    "g.df['packet_id'] = g.df.groupby('worker_assignment')['worker_assignment'].transform(assign_packets)\n",
    "\n",
    "ada = adagrid.Adagrid(ZTest1D, g, db, AdaValidate, print, None, kwargs, worker_id = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>theta0</th>\n",
       "      <th>radii0</th>\n",
       "      <th>null_truth0</th>\n",
       "      <th>worker_assignment</th>\n",
       "      <th>packet_id</th>\n",
       "      <th>K</th>\n",
       "      <th>step_id</th>\n",
       "      <th>step_iter</th>\n",
       "      <th>creator_id</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4496866493040164876</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.99950</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4496866493040164891</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.99890</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4496866493040164894</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.99878</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4496866493040164912</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.99806</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4496866493040164970</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.99574</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>4496866493040189773</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00362</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>4496866493040189787</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00306</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>4496866493040189812</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00206</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>4496866493040189826</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00150</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>4496866493040189832</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00126</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.676051e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id  parent_id   theta0   radii0  null_truth0  \\\n",
       "0      4496866493040164876          0 -0.99950  0.00002            1   \n",
       "1      4496866493040164891          0 -0.99890  0.00002            1   \n",
       "2      4496866493040164894          0 -0.99878  0.00002            1   \n",
       "3      4496866493040164912          0 -0.99806  0.00002            1   \n",
       "4      4496866493040164970          0 -0.99574  0.00002            1   \n",
       "...                    ...        ...      ...      ...          ...   \n",
       "24995  4496866493040189773          0 -0.00362  0.00002            1   \n",
       "24996  4496866493040189787          0 -0.00306  0.00002            1   \n",
       "24997  4496866493040189812          0 -0.00206  0.00002            1   \n",
       "24998  4496866493040189826          0 -0.00150  0.00002            1   \n",
       "24999  4496866493040189832          0 -0.00126  0.00002            1   \n",
       "\n",
       "       worker_assignment  packet_id     K  step_id  step_iter  creator_id  \\\n",
       "0                      2          0  8192        0          0           1   \n",
       "1                      2          0  8192        0          0           1   \n",
       "2                      3          0  8192        0          0           1   \n",
       "3                      3          0  8192        0          0           1   \n",
       "4                      2          0  8192        0          0           1   \n",
       "...                  ...        ...   ...      ...        ...         ...   \n",
       "24995                  2          6  8192        0         24           1   \n",
       "24996                  3          6  8192        0         24           1   \n",
       "24997                  3          6  8192        0         24           1   \n",
       "24998                  3          6  8192        0         24           1   \n",
       "24999                  3          6  8192        0         24           1   \n",
       "\n",
       "       creation_time  active  \n",
       "0       1.676051e+09       1  \n",
       "1       1.676051e+09       1  \n",
       "2       1.676051e+09       1  \n",
       "3       1.676051e+09       1  \n",
       "4       1.676051e+09       1  \n",
       "...              ...     ...  \n",
       "24995   1.676051e+09       1  \n",
       "24996   1.676051e+09       1  \n",
       "24997   1.676051e+09       1  \n",
       "24998   1.676051e+09       1  \n",
       "24999   1.676051e+09       1  \n",
       "\n",
       "[25000 rows x 13 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_tiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Acquired lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2\n",
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Added worker 2 to workers set.\n",
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Extended lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2 for 30 seconds.\n",
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Extended lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2 for 30 seconds.\n",
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Extended lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2 for 30 seconds.\n",
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Extended lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2 for 30 seconds.\n",
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Extended lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2 for 30 seconds.\n",
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Removed worker 2 from workers set.\n",
      "DEBUG:confirm.adagrid:[worker_id=1] \n",
      "Successfully released lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewAdagrid:\n",
    "    def __init__(self, worker_id):\n",
    "        self.first_insert = True\n",
    "        self.worker_id = worker_id\n",
    "\n",
    "    async def process_step(self, step_id):\n",
    "        next_work = None\n",
    "        packet_id = 0\n",
    "        insert_threads = []\n",
    "        packet_id = 0\n",
    "        while True:\n",
    "            report = dict()\n",
    "            report['worker_id'] = self.worker_id\n",
    "            report['step_id'] = step_id\n",
    "            report['packet_id'] = packet_id\n",
    "\n",
    "            ########################################\n",
    "            # Get work\n",
    "            ########################################\n",
    "            def get_work():\n",
    "                return ch._query_df(\n",
    "                    db.client,\n",
    "                    f\"\"\"\n",
    "                    select * from tiles\n",
    "                        where\n",
    "                            worker_assignment = {self.worker_id}\n",
    "                            and step_id = {step_id}\n",
    "                            and packet_id = {packet_id}\n",
    "                    \"\"\",\n",
    "                )\n",
    "\n",
    "            start = time.time()\n",
    "            # On the first loop, we won't have queued any work queries yet.\n",
    "            if next_work is None:\n",
    "                next_work = asyncio.to_thread(get_work)\n",
    "            work = await next_work\n",
    "            report['n_tiles'] = work.shape[0]\n",
    "\n",
    "            # Empty packet is an indication that we are done with this step.\n",
    "            if work.shape[0] == 0:\n",
    "                report['status'] = 'PACKET_DONE'\n",
    "                insert_threads.append(asyncio.to_thread(db.insert_report, report))\n",
    "                report['runtime_done_wait'] = time.time() - start\n",
    "                await asyncio.gather(*insert_threads)\n",
    "                break\n",
    "\n",
    "            # Queue a query for the next packet.\n",
    "            next_work = asyncio.to_thread(get_work)\n",
    "\n",
    "            # Check if some other worker has already inserted this packet.\n",
    "            packet_flag = f\"{job_id}:worker_{self.worker_id}_step_{step_id}_packet_{packet_id}_insert\"\n",
    "            flag = redis_con.get(packet_flag)\n",
    "            if flag is not None:\n",
    "                logger.debug(\n",
    "                    \"Skipping packet. Flag \"\n",
    "                    f\"{packet_flag} is set by worker_id={flag.decode('ascii')}.\"\n",
    "                )\n",
    "                packet_id += 1\n",
    "                report[\"runtime_skip_packet\"] = time.time() - start\n",
    "                report[\"status\"] = 'SKIPPED'\n",
    "                insert_threads.append(asyncio.to_thread(db.insert_report, report))\n",
    "                continue\n",
    "            report[\"runtime_get_work\"] = time.time() - start\n",
    "\n",
    "            ########################################\n",
    "            # Process tiles\n",
    "            ########################################\n",
    "            start = time.time()\n",
    "            results_df = ada.algo.process_tiles(tiles_df=work, report=report)\n",
    "            report[\"runtime_process_tiles\"] = time.time() - start\n",
    "\n",
    "            ########################################\n",
    "            # Insert results\n",
    "            ########################################\n",
    "            start = time.time()\n",
    "            was_flag_set = redis_con.setnx(packet_flag, self.worker_id)\n",
    "            if was_flag_set == 0:\n",
    "                logger.warning(\n",
    "                    f\"(step_id={step_id}, packet_id={packet_id})\"\n",
    "                    \" already inserted, discarding results.\"\n",
    "                )\n",
    "                report['status'] = 'DISCARDED'\n",
    "            else:\n",
    "                if self.first_insert:\n",
    "                    # Do the first insert synchronously to make sure the results table is created.\n",
    "                    db.insert_results(results_df, \"total_cost_order, tie_bound_order\")\n",
    "                    self.first_insert = False\n",
    "                else:\n",
    "                    insert_threads.append(\n",
    "                        asyncio.to_thread(\n",
    "                            db.insert_results,\n",
    "                            results_df,\n",
    "                            \"total_cost_order, tie_bound_order\",\n",
    "                        )\n",
    "                    )\n",
    "                logger.debug(\n",
    "                    \"inserted packet results for \"\n",
    "                    f\"(step_id = {step_id}, packet_id={packet_id})\"\n",
    "                    f\" with {results_df.shape[0]} results\"\n",
    "                )\n",
    "                report['status'] = 'WORK'\n",
    "            insert_threads.append(asyncio.to_thread(db.insert_report, report))\n",
    "            report[\"runtime_insert_results\"] = time.time() - start\n",
    "            packet_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "Acquired lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "Added worker 2 to workers set.\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "Extended lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2 for 30 seconds.\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=2] \n",
      "writing 2000 results\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "inserted packet results for (step_id = 0, packet_id=0) with 2000 results\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "inserted packet results for (step_id = 0, packet_id=1) with 2000 results\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "inserted packet results for (step_id = 0, packet_id=2) with 2000 results\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "inserted packet results for (step_id = 0, packet_id=3) with 2000 results\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "inserted packet results for (step_id = 0, packet_id=4) with 2000 results\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "inserted packet results for (step_id = 0, packet_id=5) with 2000 results\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "inserted packet results for (step_id = 0, packet_id=6) with 500 results\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=2] \n",
      "writing 2000 results\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=2] \n",
      "writing 2000 results\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=2] \n",
      "writing 2000 results\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=2] \n",
      "writing 2000 results\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=2] \n",
      "writing 2000 results\n",
      "DEBUG:confirm.cloud.clickhouse:[worker_id=2] \n",
      "writing 500 results\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: t2n4z83v82.us-east-1.aws.clickhouse.cloud. Connection pool size: 8\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: t2n4z83v82.us-east-1.aws.clickhouse.cloud. Connection pool size: 8\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: t2n4z83v82.us-east-1.aws.clickhouse.cloud. Connection pool size: 8\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: t2n4z83v82.us-east-1.aws.clickhouse.cloud. Connection pool size: 8\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: t2n4z83v82.us-east-1.aws.clickhouse.cloud. Connection pool size: 8\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "Removed worker 2 from workers set.\n",
      "DEBUG:confirm.adagrid:[worker_id=2] \n",
      "Successfully released lock 14e0a625ccff46c68a11992f31f08558:heartbeat_lock_2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished step\n"
     ]
    }
   ],
   "source": [
    "import imprint.log\n",
    "worker_id = initial_worker_ids[0]\n",
    "imprint.log.worker_id.set(worker_id)\n",
    "\n",
    "ada_new = NewAdagrid(worker_id)\n",
    "async with HeartbeatThread(worker_id):\n",
    "    await ada_new.process_step(0)\n",
    "    print(\"finished step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worst_tile(db, worker_id, order_col):\n",
    "    return ch._query_df(\n",
    "        db.client,\n",
    "        f\"\"\"\n",
    "        select * from results r\n",
    "            where\n",
    "                active=true\n",
    "                and id not in (select id from inactive)\n",
    "                and worker_assignment = {worker_id}\n",
    "        order by {order_col} limit 1\n",
    "    \"\"\",\n",
    "    )\n",
    "# db.n_processed_tiles(0)\n",
    "# ada.algo.convergence_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_step(self, tiles_df, new_step_id, report):\n",
    "    tiles_df[\"finisher_id\"] = self.cfg[\"worker_id\"]\n",
    "    tiles_df[\"active\"] = ~(tiles_df[\"refine\"] | tiles_df[\"deepen\"])\n",
    "\n",
    "    # Record what we decided to do.\n",
    "    if \"split\" not in tiles_df.columns:\n",
    "        tiles_df[\"split\"] = False\n",
    "    done_cols = [\n",
    "        \"id\",\n",
    "        \"step_id\",\n",
    "        \"step_iter\",\n",
    "        \"active\",\n",
    "        \"finisher_id\",\n",
    "        \"refine\",\n",
    "        \"deepen\",\n",
    "        \"split\",\n",
    "    ]\n",
    "    # TODO: call finish in separate thread to avoid blocking\n",
    "    self.db.finish(tiles_df[done_cols])\n",
    "\n",
    "    n_refine = tiles_df[\"refine\"].sum()\n",
    "    n_deepen = tiles_df[\"deepen\"].sum()\n",
    "    report.update(\n",
    "        dict(\n",
    "            n_refine=n_refine,\n",
    "            n_deepen=n_deepen,\n",
    "            n_complete=tiles_df[\"active\"].sum(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    nothing_to_do = n_refine == 0 and n_deepen == 0\n",
    "    if nothing_to_do:\n",
    "        return \"empty\"\n",
    "\n",
    "    # Actually deepen and refine!\n",
    "    g = refine_and_deepen(\n",
    "        tiles_df, self.null_hypos, self.cfg[\"max_K\"], self.cfg[\"worker_id\"]\n",
    "    )\n",
    "    g.df[\"step_id\"] = new_step_id\n",
    "    g.df[\"creator_id\"] = self.cfg[\"worker_id\"]\n",
    "    g.df[\"creation_time\"] = imprint.timer.simple_timer()\n",
    "\n",
    "    # there might be new inactive tiles that resulted from splitting with\n",
    "    # the null hypotheses. we need to mark these tiles as finished.\n",
    "    # TODO: inactive insert_tiles and finish can be done in separate thread\n",
    "    # to avoid blocking\n",
    "    inactive_df = g.df[~g.df[\"active\"]].copy()\n",
    "    inactive_df[\"step_iter\"] = np.int32(-1)\n",
    "    self.db.insert_tiles(inactive_df)\n",
    "    inactive_df[\"refine\"] = False\n",
    "    inactive_df[\"deepen\"] = False\n",
    "    inactive_df[\"split\"] = True\n",
    "    inactive_df[\"finisher_id\"] = self.cfg[\"worker_id\"]\n",
    "    self.db.finish(inactive_df[done_cols])\n",
    "\n",
    "    # Assign tiles to packets and then insert them into the database for\n",
    "    # processing.\n",
    "    g_active = g.prune_inactive()\n",
    "    g_active.df[\"step_iter\"], n_packets = step_iter_assignments(\n",
    "        g_active.df, self.cfg[\"packet_size\"]\n",
    "    )\n",
    "    # TODO: i think insert_tiles can be done in separate thread to avoid\n",
    "    # blocking\n",
    "    self.db.insert_tiles(g_active.df)\n",
    "    self.db.set_step_info(\n",
    "        step_id=new_step_id, step_iter=0, n_iter=n_packets, n_tiles=g_active.n_tiles\n",
    "    )\n",
    "\n",
    "    logger.debug(\n",
    "        f\"new step {(new_step_id, 0, n_packets, g.n_tiles)}\\n\"\n",
    "        f\"n_tiles={g_active.n_tiles} packet_size={self.cfg['packet_size']}\\n\"\n",
    "        f\"n_inactive_tiles={inactive_df.shape[0]}\"\n",
    "    )\n",
    "    report.update(\n",
    "        dict(\n",
    "            n_new_tiles=g.n_tiles,\n",
    "            new_K_distribution=g.df[\"K\"].value_counts().to_dict(),\n",
    "        )\n",
    "    )\n",
    "    return new_step_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': False,\n",
       " 'max_tie_est': 0.02355957,\n",
       " 'next_tile_tie_est': 0.0235595703125,\n",
       " 'next_tile_tie_bound': 0.027757570147514343,\n",
       " 'next_tile_sim_cost': 0.004196513078392677,\n",
       " 'next_tile_grid_cost': 1.4867566216665573e-06,\n",
       " 'next_tile_total_cost': 0.004197999835014343,\n",
       " 'next_tile_K': 8192.0,\n",
       " 'next_tile_at_max_K': False}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: if n_processed_tiles == step_n_tiles:\n",
    "report = dict()\n",
    "step_id = 0\n",
    "ada.algo.c[\"worker_id\"] = worker_id\n",
    "start = time.time()\n",
    "converged, convergence_data = ada.algo.convergence_criterion(report)\n",
    "report[\"runtime_convergence_criterion\"] = time.time() - start\n",
    "if converged:\n",
    "    report[\"status\"] = \"CONVERGED\"\n",
    "    logger.debug(\"Convergence!!\")\n",
    "    # TODO: return\n",
    "elif step_id >= ada.algo.c[\"n_steps\"] - 1:\n",
    "    report[\"status\"] = \"MAX_STEPS\"\n",
    "    print(\"max steps\")\n",
    "    # TODO: end the job.\n",
    "else:\n",
    "    # If we haven't converged, we create a new step.\n",
    "    start = time.time()\n",
    "    new_step_id = step_id + 1\n",
    "    tiles_df = ada.algo.select_tiles(report, convergence_data)\n",
    "    report[\"runtime_select_tiles\"] = time.time() - start\n",
    "\n",
    "    if tiles_df is None:\n",
    "        # New step is empty so we have terminated but\n",
    "        # failed to converge.\n",
    "        logger.debug(\n",
    "            \"New packet is empty. Waiting for the next \"\n",
    "            \"coordination despite failure to converge.\"\n",
    "        )\n",
    "        report['status'] = 'EMPTY_STEP'\n",
    "        # TODO: wait for coordination\n",
    "    else:\n",
    "        report[\"status\"] = \"NEW_STEP\"\n",
    "        report[\"n_tiles\"] = tiles_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 0.02355957)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = dict()\n",
    "max_tie_est = worst_tile(db, worker_id, \"tie_est desc\")[\"tie_est\"].iloc[0]\n",
    "next_tile = worst_tile(db, worker_id, \"total_cost_order, tie_bound_order\").iloc[0]\n",
    "report['converged'] = ada.algo._are_tiles_done(next_tile, max_tie_est)\n",
    "report.update(\n",
    "    dict(\n",
    "        max_tie_est=max_tie_est,\n",
    "        next_tile_tie_est=next_tile[\"tie_est\"],\n",
    "        next_tile_tie_bound=next_tile[\"tie_bound\"],\n",
    "        next_tile_sim_cost=next_tile[\"sim_cost\"],\n",
    "        next_tile_grid_cost=next_tile[\"grid_cost\"],\n",
    "        next_tile_total_cost=next_tile[\"total_cost\"],\n",
    "        next_tile_K=next_tile[\"K\"],\n",
    "        next_tile_at_max_K=next_tile[\"K\"] == ada.algo.max_K,\n",
    "    )\n",
    ")\n",
    "report['converged'], max_tie_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'converged': False,\n",
       " 'max_tie_est': 0.02355957,\n",
       " 'next_tile_tie_est': 0.0235595703125,\n",
       " 'next_tile_tie_bound': 0.027757570147514343,\n",
       " 'next_tile_sim_cost': 0.004196513078392677,\n",
       " 'next_tile_grid_cost': 1.4867566216665573e-06,\n",
       " 'next_tile_total_cost': 0.004197999835014343,\n",
       " 'next_tile_K': 8192.0,\n",
       " 'next_tile_at_max_K': False}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>step_id</th>\n",
       "      <th>packet_id</th>\n",
       "      <th>n_tiles</th>\n",
       "      <th>runtime_get_work</th>\n",
       "      <th>runtime_process_tiles</th>\n",
       "      <th>status</th>\n",
       "      <th>runtime_insert_results</th>\n",
       "      <th>runtime_done_wait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.391095</td>\n",
       "      <td>0.225258</td>\n",
       "      <td>WORK</td>\n",
       "      <td>0.915440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.096891</td>\n",
       "      <td>0.023989</td>\n",
       "      <td>WORK</td>\n",
       "      <td>0.037790</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.096089</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>WORK</td>\n",
       "      <td>0.041483</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.095760</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>WORK</td>\n",
       "      <td>0.041628</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.095944</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>WORK</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>500</td>\n",
       "      <td>0.066075</td>\n",
       "      <td>0.104144</td>\n",
       "      <td>WORK</td>\n",
       "      <td>0.036042</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.157111</td>\n",
       "      <td>0.022715</td>\n",
       "      <td>WORK</td>\n",
       "      <td>0.038953</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PACKET_DONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker_id  step_id  packet_id  n_tiles  runtime_get_work  \\\n",
       "0          2        0          0     2000          0.391095   \n",
       "1          2        0          3     2000          0.096891   \n",
       "2          2        0          5     2000          0.096089   \n",
       "3          2        0          2     2000          0.095760   \n",
       "4          2        0          4     2000          0.095944   \n",
       "5          2        0          6      500          0.066075   \n",
       "6          2        0          1     2000          0.157111   \n",
       "7          2        0          7        0               NaN   \n",
       "\n",
       "   runtime_process_tiles       status  runtime_insert_results  \\\n",
       "0               0.225258         WORK                0.915440   \n",
       "1               0.023989         WORK                0.037790   \n",
       "2               0.020335         WORK                0.041483   \n",
       "3               0.019291         WORK                0.041628   \n",
       "4               0.023964         WORK                0.037034   \n",
       "5               0.104144         WORK                0.036042   \n",
       "6               0.022715         WORK                0.038953   \n",
       "7                    NaN  PACKET_DONE                     NaN   \n",
       "\n",
       "   runtime_done_wait  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "5                NaN  \n",
       "6                NaN  \n",
       "7           0.033856  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_reports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confirm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4c6ec5b2d6c7b38df115d547b82cd53ca25eea58d87299956d35a9dc79f19f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
