{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking to inform the Model API design.\n",
    "\n",
    "I had several question that are important to answer to not hamstring our\n",
    "performance when we start to commit to a Model API:\n",
    "\n",
    "1. Does slicing and copying a large array of uniforms (or other pregenerated random variates) cause performance issues?\n",
    "    - No! It does not. This is irrelevant even though I had previously\n",
    "      suspected this was a significant cause of performance problems. Both the\n",
    "      microbenchmark and later full benchmark demonstrate this. This\n",
    "      is true across CPU and GPU.\n",
    "2. What batch size should we use?\n",
    "    - Larger when the simulation function is slower. (duh)\n",
    "    - 1024 sims x 64 pts is reasonable for something like Lei.\n",
    "    - On CPU: Large-ish but it's actually faster to use some batches rather than\n",
    "      running the whole thing at once. This is unsurprising and due to\n",
    "      cache-friendliness. Ideal was 32768 sims and 128 grid points in a single batch.\n",
    "    - On GPU:\n",
    "3. Are the concatenations in our current GPU code problematic.\n",
    "    - On CPU: Yes, concatenation is bad for performance, especially when we're\n",
    "      double batching over both grid points and simulations since we incur a\n",
    "      concatenation for each outer batch.\n",
    "    - On GPU: CHECK THIS! This will be especially bad because we force blocking\n",
    "      and copy data from GPU to CPU.\n",
    "4. Does it help to include the summation of rejections inside the jitted function call? Or can we factor that out into the calling code?\n",
    "    - On CPU, we get better performance when we include the summation inside the jit call.\n",
    "    - On GPU: CHECK THIS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def6611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confirm.outlaw.nb_util import setup_nb\n",
    "\n",
    "setup_nb()\n",
    "\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from confirm.lewislib import batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is copying the uniforms array expensive?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifs = jax.random.uniform(jax.random.PRNGKey(0), (256000, 350, 4))\n",
    "unifs10 = jax.random.uniform(jax.random.PRNGKey(0), (10000, 350, 4))\n",
    "unifs2d = jax.random.uniform(jax.random.PRNGKey(0), (256000, 350, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum 0.04343724250793457\n",
      "copy 0.31673121452331543\n",
      "slicesum 0.22755980491638184\n",
      "batched sum 0.21455097198486328\n",
      "sum10k no slice 0.0024559497833251953\n",
      "sum10k with slice 0.009029865264892578\n",
      "sum2d no slice 0.008322954177856445\n",
      "sum2d with slice 0.07137775421142578\n",
      "sum 0.04260683059692383\n",
      "copy 0.30614209175109863\n",
      "slicesum 0.2239699363708496\n",
      "batched sum 0.20693397521972656\n",
      "sum10k no slice 0.0021729469299316406\n",
      "sum10k with slice 0.007977962493896484\n",
      "sum2d no slice 0.008790016174316406\n",
      "sum2d with slice 0.06688880920410156\n",
      "sum 0.03954720497131348\n",
      "copy 0.29372501373291016\n",
      "slicesum 0.2198009490966797\n",
      "batched sum 0.2037220001220703\n",
      "sum10k no slice 0.0016851425170898438\n",
      "sum10k with slice 0.008710145950317383\n",
      "sum2d no slice 0.009112834930419922\n",
      "sum2d with slice 0.07049393653869629\n"
     ]
    }
   ],
   "source": [
    "for k in range(4):\n",
    "    start = time.time()\n",
    "    out1 = unifs.sum(axis=1).block_until_ready()\n",
    "    if k >= 1:\n",
    "        print(\"sum\", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    copy = unifs.copy().block_until_ready()\n",
    "    if k >= 1:\n",
    "        print(\"copy\", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    out2 = unifs[:-1].sum(axis=1).block_until_ready()\n",
    "    if k >= 1:\n",
    "        print(\"slicesum\", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    outs = []\n",
    "    for i in range(0, unifs.shape[0], 10000):\n",
    "        begin_idx = i\n",
    "        end_idx = min(i + 10000, unifs.shape[0])\n",
    "        outs.append(unifs[begin_idx:end_idx].sum(axis=1))\n",
    "    out2 = jnp.concatenate(outs).block_until_ready()\n",
    "    if k >= 1:\n",
    "        print(\"batched sum\", time.time() - start)\n",
    "    np.testing.assert_allclose(out1, out2)\n",
    "\n",
    "    start = time.time()\n",
    "    unifs10.sum(axis=1).block_until_ready()\n",
    "    if k >= 1:\n",
    "        print(\"sum10k no slice\", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    unifs[:10000].sum(axis=1).block_until_ready()\n",
    "    if k >= 1:\n",
    "        print(\"sum10k with slice\", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    unifs2d.sum(axis=1).block_until_ready()\n",
    "    if k >= 1:\n",
    "        print(\"sum2d no slice\", time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    unifs[:, :, :1].sum(axis=1).block_until_ready()\n",
    "    if k >= 1:\n",
    "        print(\"sum2d with slice\", time.time() - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What batch sizes??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(p, unifs):\n",
    "    return jnp.sum(unifs[:, :] < p[None, :]) / unifs.size\n",
    "\n",
    "\n",
    "def stat(theta, null_truth, unifs):\n",
    "    p = jax.scipy.special.expit(theta)\n",
    "    simulatev = jax.vmap(simulator, in_axes=(None, 0))\n",
    "    test_stats = simulatev(p, unifs)\n",
    "    false_test_stats = jnp.where(null_truth[0], test_stats, 100.0)\n",
    "    return false_test_stats\n",
    "\n",
    "\n",
    "statv = jax.jit(jax.vmap(stat, in_axes=(0, 0, None)))\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def stat_sum(lam, theta, null_truth, unifs):\n",
    "    stats = jax.vmap(stat, in_axes=(0, 0, None))(theta, null_truth, unifs)\n",
    "    return jnp.sum(stats < lam, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1024\n",
    "theta = np.random.rand(N, 4)\n",
    "null_truth = np.ones((N, 3), dtype=bool)\n",
    "sim_sizes = np.full(N, 2**13)\n",
    "lam = 0.05"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, I'm comparing several things:\n",
    "1. How does the batch size affect the output? \n",
    "    - caution: I think this is quite different on GPU versus CPU. JAX on GPU\n",
    "      pipelines GPU calls as long as we don't block and wait for the results.\n",
    "      So, smaller batches are acceptable on the GPU.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple(unifs_chunk, _1, _2):\n",
    "    return stat_sum(\n",
    "        lam,\n",
    "        theta,\n",
    "        null_truth,\n",
    "        unifs_chunk,\n",
    "    ).block_until_ready()\n",
    "\n",
    "\n",
    "def batched(unifs_chunk, sim_batch_size, grid_batch_size):\n",
    "    batched_stat_sum = batch.batch(\n",
    "        batch.batch(stat_sum, sim_batch_size, in_axes=(None, None, None, 0)),\n",
    "        grid_batch_size,\n",
    "        in_axes=(None, 0, 0, None),\n",
    "    )\n",
    "    return batched_stat_sum(lam, theta, null_truth, unifs_chunk)\n",
    "\n",
    "\n",
    "def late_concat_batch(unifs_chunk, sim_batch_size, grid_batch_size):\n",
    "    rejs = []\n",
    "    for i in range(0, unifs_chunk.shape[0], sim_batch_size):\n",
    "        i_begin = i\n",
    "        i_end = min(unifs_chunk.shape[0], i + sim_batch_size)\n",
    "        for j in range(0, theta.shape[0], grid_batch_size):\n",
    "            j_begin = j\n",
    "            j_end = min(theta.shape[0], j + grid_batch_size)\n",
    "            subunifs_chunk = unifs_chunk[i_begin:i_end]\n",
    "            rejs.append(\n",
    "                stat_sum(\n",
    "                    lam,\n",
    "                    theta[j_begin:j_end],\n",
    "                    null_truth[j_begin:j_end],\n",
    "                    subunifs_chunk,\n",
    "                )\n",
    "            )\n",
    "    return jnp.concatenate(rejs).block_until_ready()\n",
    "\n",
    "\n",
    "def late_concat_stat_then_sum(unifs_chunk, sim_batch_size, grid_batch_size):\n",
    "    rejs = []\n",
    "    for i in range(0, unifs_chunk.shape[0], sim_batch_size):\n",
    "        i_begin = i\n",
    "        i_end = min(unifs_chunk.shape[0], i + sim_batch_size)\n",
    "        for j in range(0, theta.shape[0], grid_batch_size):\n",
    "            j_begin = j\n",
    "            j_end = min(theta.shape[0], j + grid_batch_size)\n",
    "            subunifs_chunk = unifs_chunk[i_begin:i_end]\n",
    "            stats = statv(\n",
    "                theta[j_begin:j_end],\n",
    "                null_truth[j_begin:j_end],\n",
    "                subunifs_chunk,\n",
    "            )\n",
    "            rejs.append(jnp.sum(stats < lam, axis=-1))\n",
    "    return jnp.concatenate(rejs).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "fncs = dict(\n",
    "    simple=simple,\n",
    "    batched=batched,\n",
    "    late_concat_batch=late_concat_batch,\n",
    "    late_concat_stat_then_sum=late_concat_stat_then_sum,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "simple (1024, 32) = 0.018233060836791992\n",
      "batched (1024, 32) = 2.3820278644561768\n",
      "late_concat_batch (1024, 32) = 0.8279647827148438\n",
      "late_concat_stat_then_sum (1024, 32) = 0.8557298183441162\n",
      " \n",
      "simple (1024, 64) = 0.017095088958740234\n",
      "batched (1024, 64) = 1.1565570831298828\n",
      "late_concat_batch (1024, 64) = 0.4140758514404297\n",
      "late_concat_stat_then_sum (1024, 64) = 0.4697558879852295\n",
      " \n",
      "simple (1024, 128) = 0.018488168716430664\n",
      "batched (1024, 128) = 0.6148321628570557\n",
      "late_concat_batch (1024, 128) = 0.22803211212158203\n",
      "late_concat_stat_then_sum (1024, 128) = 0.26714372634887695\n",
      " \n",
      "simple (1024, 256) = 0.018473148345947266\n",
      "batched (1024, 256) = 0.3247189521789551\n",
      "late_concat_batch (1024, 256) = 0.12849926948547363\n",
      "late_concat_stat_then_sum (1024, 256) = 0.1658928394317627\n",
      " \n",
      "simple (1024, 512) = 0.01674818992614746\n",
      "batched (1024, 512) = 0.17656707763671875\n",
      "late_concat_batch (1024, 512) = 0.08060789108276367\n",
      "late_concat_stat_then_sum (1024, 512) = 0.10544490814208984\n",
      " \n",
      "simple (1024, 1024) = 0.01740407943725586\n",
      "batched (1024, 1024) = 0.09078788757324219\n",
      "late_concat_batch (1024, 1024) = 0.04300212860107422\n",
      "late_concat_stat_then_sum (1024, 1024) = 0.06878280639648438\n",
      " \n",
      " \n",
      "simple (2048, 32) = 0.01782703399658203\n",
      "batched (2048, 32) = 1.2317321300506592\n",
      "late_concat_batch (2048, 32) = 0.4274909496307373\n",
      "late_concat_stat_then_sum (2048, 32) = 0.4808940887451172\n",
      " \n",
      "simple (2048, 64) = 0.0195620059967041\n",
      "batched (2048, 64) = 0.7302289009094238\n",
      "late_concat_batch (2048, 64) = 0.2661929130554199\n",
      "late_concat_stat_then_sum (2048, 64) = 0.3080408573150635\n",
      " \n",
      "simple (2048, 128) = 0.019253015518188477\n",
      "batched (2048, 128) = 0.3482081890106201\n",
      "late_concat_batch (2048, 128) = 0.1694478988647461\n",
      "late_concat_stat_then_sum (2048, 128) = 0.1936659812927246\n",
      " \n",
      "simple (2048, 256) = 0.018439054489135742\n",
      "batched (2048, 256) = 0.1870739459991455\n",
      "late_concat_batch (2048, 256) = 0.08449101448059082\n",
      "late_concat_stat_then_sum (2048, 256) = 0.11008691787719727\n",
      " \n",
      "simple (2048, 512) = 0.01774907112121582\n",
      "batched (2048, 512) = 0.09145092964172363\n",
      "late_concat_batch (2048, 512) = 0.04094409942626953\n",
      "late_concat_stat_then_sum (2048, 512) = 0.06044125556945801\n",
      " \n",
      "simple (2048, 1024) = 0.019581079483032227\n",
      "batched (2048, 1024) = 0.059873104095458984\n",
      "late_concat_batch (2048, 1024) = 0.033516883850097656\n",
      "late_concat_stat_then_sum (2048, 1024) = 0.054533958435058594\n",
      " \n",
      " \n",
      "simple (4096, 32) = 0.016790151596069336\n",
      "batched (4096, 32) = 0.6886060237884521\n",
      "late_concat_batch (4096, 32) = 0.2533419132232666\n",
      "late_concat_stat_then_sum (4096, 32) = 0.29600095748901367\n",
      " \n",
      "simple (4096, 64) = 0.01967310905456543\n",
      "batched (4096, 64) = 0.35512781143188477\n",
      "late_concat_batch (4096, 64) = 0.13933372497558594\n",
      "late_concat_stat_then_sum (4096, 64) = 0.16745591163635254\n",
      " \n",
      "simple (4096, 128) = 0.018852710723876953\n",
      "batched (4096, 128) = 0.18848800659179688\n",
      "late_concat_batch (4096, 128) = 0.08491802215576172\n",
      "late_concat_stat_then_sum (4096, 128) = 0.11201095581054688\n",
      " \n",
      "simple (4096, 256) = 0.01700615882873535\n",
      "batched (4096, 256) = 0.09245491027832031\n",
      "late_concat_batch (4096, 256) = 0.041464805603027344\n",
      "late_concat_stat_then_sum (4096, 256) = 0.06190204620361328\n",
      " \n",
      "simple (4096, 512) = 0.01772785186767578\n",
      "batched (4096, 512) = 0.06060504913330078\n",
      "late_concat_batch (4096, 512) = 0.03272438049316406\n",
      "late_concat_stat_then_sum (4096, 512) = 0.056748151779174805\n",
      " \n",
      "simple (4096, 1024) = 0.017371177673339844\n",
      "batched (4096, 1024) = 0.03730201721191406\n",
      "late_concat_batch (4096, 1024) = 0.024265050888061523\n",
      "late_concat_stat_then_sum (4096, 1024) = 0.04189109802246094\n",
      " \n",
      " \n",
      "simple (8192, 32) = 0.018219947814941406\n",
      "batched (8192, 32) = 0.3700687885284424\n",
      "late_concat_batch (8192, 32) = 0.1385481357574463\n",
      "late_concat_stat_then_sum (8192, 32) = 0.17011094093322754\n",
      " \n",
      "simple (8192, 64) = 0.019215822219848633\n",
      "batched (8192, 64) = 0.20476508140563965\n",
      "late_concat_batch (8192, 64) = 0.08915209770202637\n",
      "late_concat_stat_then_sum (8192, 64) = 0.12719511985778809\n",
      " \n",
      "simple (8192, 128) = 0.01967906951904297\n",
      "batched (8192, 128) = 0.10760664939880371\n",
      "late_concat_batch (8192, 128) = 0.04460620880126953\n",
      "late_concat_stat_then_sum (8192, 128) = 0.06113386154174805\n",
      " \n",
      "simple (8192, 256) = 0.01801896095275879\n",
      "batched (8192, 256) = 0.06329488754272461\n",
      "late_concat_batch (8192, 256) = 0.03287005424499512\n",
      "late_concat_stat_then_sum (8192, 256) = 0.04841303825378418\n",
      " \n",
      "simple (8192, 512) = 0.01871800422668457\n",
      "batched (8192, 512) = 0.042633056640625\n",
      "late_concat_batch (8192, 512) = 0.025068998336791992\n",
      "late_concat_stat_then_sum (8192, 512) = 0.04299640655517578\n",
      " \n",
      "simple (8192, 1024) = 0.018262147903442383\n",
      "batched (8192, 1024) = 0.0291900634765625\n",
      "late_concat_batch (8192, 1024) = 0.023045063018798828\n",
      "late_concat_stat_then_sum (8192, 1024) = 0.039053916931152344\n",
      " \n",
      " \n",
      "simple (16384, 32) = 0.020273685455322266\n",
      "batched (16384, 32) = 0.2235558032989502\n",
      "late_concat_batch (16384, 32) = 0.08227801322937012\n",
      "late_concat_stat_then_sum (16384, 32) = 0.11156487464904785\n",
      " \n",
      "simple (16384, 64) = 0.0188140869140625\n",
      "batched (16384, 64) = 0.11078572273254395\n",
      "late_concat_batch (16384, 64) = 0.04475903511047363\n",
      "late_concat_stat_then_sum (16384, 64) = 0.06564879417419434\n",
      " \n",
      "simple (16384, 128) = 0.017961978912353516\n",
      "batched (16384, 128) = 0.06831812858581543\n",
      "late_concat_batch (16384, 128) = 0.03565216064453125\n",
      "late_concat_stat_then_sum (16384, 128) = 0.06067299842834473\n",
      " \n",
      "simple (16384, 256) = 0.0198819637298584\n",
      "batched (16384, 256) = 0.042310237884521484\n",
      "late_concat_batch (16384, 256) = 0.028105974197387695\n",
      "late_concat_stat_then_sum (16384, 256) = 0.044838905334472656\n",
      " \n",
      "simple (16384, 512) = 0.017935991287231445\n",
      "batched (16384, 512) = 0.031432151794433594\n",
      "late_concat_batch (16384, 512) = 0.021240949630737305\n",
      "late_concat_stat_then_sum (16384, 512) = 0.037499189376831055\n",
      " \n",
      "simple (16384, 1024) = 0.0174410343170166\n",
      "batched (16384, 1024) = 0.025974035263061523\n",
      "late_concat_batch (16384, 1024) = 0.020727872848510742\n",
      "late_concat_stat_then_sum (16384, 1024) = 0.03530287742614746\n",
      " \n",
      " \n",
      "simple (32768, 32) = 0.017350196838378906\n",
      "batched (32768, 32) = 0.12953591346740723\n",
      "late_concat_batch (32768, 32) = 0.025814056396484375\n",
      "late_concat_stat_then_sum (32768, 32) = 0.04740405082702637\n",
      " \n",
      "simple (32768, 64) = 0.018049001693725586\n",
      "batched (32768, 64) = 0.06943702697753906\n",
      "late_concat_batch (32768, 64) = 0.016288042068481445\n",
      "late_concat_stat_then_sum (32768, 64) = 0.033364057540893555\n",
      " \n",
      "simple (32768, 128) = 0.018035888671875\n",
      "batched (32768, 128) = 0.047554731369018555\n",
      "late_concat_batch (32768, 128) = 0.02075505256652832\n",
      "late_concat_stat_then_sum (32768, 128) = 0.038442134857177734\n",
      " \n",
      "simple (32768, 256) = 0.01833796501159668\n",
      "batched (32768, 256) = 0.034996986389160156\n",
      "late_concat_batch (32768, 256) = 0.02100515365600586\n",
      "late_concat_stat_then_sum (32768, 256) = 0.03637814521789551\n",
      " \n",
      "simple (32768, 512) = 0.018134117126464844\n",
      "batched (32768, 512) = 0.02505016326904297\n",
      "late_concat_batch (32768, 512) = 0.01910877227783203\n",
      "late_concat_stat_then_sum (32768, 512) = 0.034422874450683594\n",
      " \n",
      "simple (32768, 1024) = 0.01840996742248535\n",
      "batched (32768, 1024) = 0.021962881088256836\n",
      "late_concat_batch (32768, 1024) = 0.017310142517089844\n",
      "late_concat_stat_then_sum (32768, 1024) = 0.03353619575500488\n"
     ]
    }
   ],
   "source": [
    "unifs = jax.random.uniform(jax.random.PRNGKey(0), (32768, 1, 4))\n",
    "\n",
    "run_keys = list(fncs.keys())\n",
    "for sim_batch_size in [1024, 2048, 4096, 8192, 16384, 32768]:\n",
    "    print(\" \")\n",
    "    for grid_batch_size in [32, 64, 128, 256, 512, 1024]:\n",
    "        print(\" \")\n",
    "        for k in range(2):\n",
    "            for run_key in run_keys:\n",
    "                start = time.time()\n",
    "                result = fncs[run_key](unifs, sim_batch_size, grid_batch_size)\n",
    "                if k >= 1:\n",
    "                    print(\n",
    "                        f\"{run_key} ({sim_batch_size}, {grid_batch_size}) = {time.time() - start}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "simple (512, 32) = 0.01633596420288086\n",
      "batched (512, 32) = 2.351898193359375\n",
      "late_concat_batch (512, 32) = 0.8599920272827148\n",
      "late_concat_stat_then_sum (512, 32) = 0.9273097515106201\n",
      " \n",
      "simple (512, 64) = 0.016728878021240234\n",
      "batched (512, 64) = 1.2322278022766113\n",
      "late_concat_batch (512, 64) = 0.4427659511566162\n",
      "late_concat_stat_then_sum (512, 64) = 0.49536800384521484\n",
      " \n",
      "simple (512, 128) = 0.016174793243408203\n",
      "batched (512, 128) = 0.6040279865264893\n",
      "late_concat_batch (512, 128) = 0.219649076461792\n",
      "late_concat_stat_then_sum (512, 128) = 0.2473299503326416\n",
      " \n",
      "simple (512, 256) = 0.01509404182434082\n",
      "batched (512, 256) = 0.3037099838256836\n",
      "late_concat_batch (512, 256) = 0.12256622314453125\n",
      "late_concat_stat_then_sum (512, 256) = 0.1425340175628662\n",
      " \n",
      "simple (512, 512) = 0.015145063400268555\n",
      "batched (512, 512) = 0.16445422172546387\n",
      "late_concat_batch (512, 512) = 0.07249689102172852\n",
      "late_concat_stat_then_sum (512, 512) = 0.09273791313171387\n",
      " \n",
      "simple (512, 1024) = 0.016646146774291992\n",
      "batched (512, 1024) = 0.10298395156860352\n",
      "late_concat_batch (512, 1024) = 0.058409929275512695\n",
      "late_concat_stat_then_sum (512, 1024) = 0.07105612754821777\n",
      " \n",
      " \n",
      "simple (1024, 32) = 0.016386985778808594\n",
      "batched (1024, 32) = 1.2114417552947998\n",
      "late_concat_batch (1024, 32) = 0.4430820941925049\n",
      "late_concat_stat_then_sum (1024, 32) = 0.4635040760040283\n",
      " \n",
      "simple (1024, 64) = 0.015426158905029297\n",
      "batched (1024, 64) = 0.5882117748260498\n",
      "late_concat_batch (1024, 64) = 0.21935772895812988\n",
      "late_concat_stat_then_sum (1024, 64) = 0.24840998649597168\n",
      " \n",
      "simple (1024, 128) = 0.014616012573242188\n",
      "batched (1024, 128) = 0.3059546947479248\n",
      "late_concat_batch (1024, 128) = 0.1240999698638916\n",
      "late_concat_stat_then_sum (1024, 128) = 0.15583419799804688\n",
      " \n",
      "simple (1024, 256) = 0.01577591896057129\n",
      "batched (1024, 256) = 0.16978096961975098\n",
      "late_concat_batch (1024, 256) = 0.0780949592590332\n",
      "late_concat_stat_then_sum (1024, 256) = 0.09364676475524902\n",
      " \n",
      "simple (1024, 512) = 0.017033100128173828\n",
      "batched (1024, 512) = 0.09791421890258789\n",
      "late_concat_batch (1024, 512) = 0.051094770431518555\n",
      "late_concat_stat_then_sum (1024, 512) = 0.06125020980834961\n",
      " \n",
      "simple (1024, 1024) = 0.015581130981445312\n",
      "batched (1024, 1024) = 0.052137136459350586\n",
      "late_concat_batch (1024, 1024) = 0.02930426597595215\n",
      "late_concat_stat_then_sum (1024, 1024) = 0.039103031158447266\n",
      " \n",
      " \n",
      "simple (2048, 32) = 0.016941070556640625\n",
      "batched (2048, 32) = 0.5924208164215088\n",
      "late_concat_batch (2048, 32) = 0.22616815567016602\n",
      "late_concat_stat_then_sum (2048, 32) = 0.28145909309387207\n",
      " \n",
      "simple (2048, 64) = 0.01603984832763672\n",
      "batched (2048, 64) = 0.33838486671447754\n",
      "late_concat_batch (2048, 64) = 0.13364291191101074\n",
      "late_concat_stat_then_sum (2048, 64) = 0.16097307205200195\n",
      " \n",
      "simple (2048, 128) = 0.016010046005249023\n",
      "batched (2048, 128) = 0.17673993110656738\n",
      "late_concat_batch (2048, 128) = 0.08335471153259277\n",
      "late_concat_stat_then_sum (2048, 128) = 0.09801912307739258\n",
      " \n",
      "simple (2048, 256) = 0.017051219940185547\n",
      "batched (2048, 256) = 0.09794306755065918\n",
      "late_concat_batch (2048, 256) = 0.049590110778808594\n",
      "late_concat_stat_then_sum (2048, 256) = 0.059597015380859375\n",
      " \n",
      "simple (2048, 512) = 0.01512598991394043\n",
      "batched (2048, 512) = 0.05329608917236328\n",
      "late_concat_batch (2048, 512) = 0.03026294708251953\n",
      "late_concat_stat_then_sum (2048, 512) = 0.0391850471496582\n",
      " \n",
      "simple (2048, 1024) = 0.015951871871948242\n",
      "batched (2048, 1024) = 0.03405475616455078\n",
      "late_concat_batch (2048, 1024) = 0.02562999725341797\n",
      "late_concat_stat_then_sum (2048, 1024) = 0.03100872039794922\n",
      " \n",
      " \n",
      "simple (4096, 32) = 0.015563011169433594\n",
      "batched (4096, 32) = 0.32006096839904785\n",
      "late_concat_batch (4096, 32) = 0.1233072280883789\n",
      "late_concat_stat_then_sum (4096, 32) = 0.14644885063171387\n",
      " \n",
      "simple (4096, 64) = 0.015822887420654297\n",
      "batched (4096, 64) = 0.17481207847595215\n",
      "late_concat_batch (4096, 64) = 0.07800722122192383\n",
      "late_concat_stat_then_sum (4096, 64) = 0.0974881649017334\n",
      " \n",
      "simple (4096, 128) = 0.016840219497680664\n",
      "batched (4096, 128) = 0.09879088401794434\n",
      "late_concat_batch (4096, 128) = 0.048660993576049805\n",
      "late_concat_stat_then_sum (4096, 128) = 0.06233024597167969\n",
      " \n",
      "simple (4096, 256) = 0.01668095588684082\n",
      "batched (4096, 256) = 0.05469393730163574\n",
      "late_concat_batch (4096, 256) = 0.031218767166137695\n",
      "late_concat_stat_then_sum (4096, 256) = 0.04008984565734863\n",
      " \n",
      "simple (4096, 512) = 0.01687788963317871\n",
      "batched (4096, 512) = 0.03356170654296875\n",
      "late_concat_batch (4096, 512) = 0.021524906158447266\n",
      "late_concat_stat_then_sum (4096, 512) = 0.0303800106048584\n",
      " \n",
      "simple (4096, 1024) = 0.017123937606811523\n",
      "batched (4096, 1024) = 0.027478933334350586\n",
      "late_concat_batch (4096, 1024) = 0.020513057708740234\n",
      "late_concat_stat_then_sum (4096, 1024) = 0.030028104782104492\n",
      " \n",
      " \n",
      "simple (8192, 32) = 0.01552891731262207\n",
      "batched (8192, 32) = 0.1933438777923584\n",
      "late_concat_batch (8192, 32) = 0.08370280265808105\n",
      "late_concat_stat_then_sum (8192, 32) = 0.10272812843322754\n",
      " \n",
      "simple (8192, 64) = 0.016503095626831055\n",
      "batched (8192, 64) = 0.11158227920532227\n",
      "late_concat_batch (8192, 64) = 0.05423784255981445\n",
      "late_concat_stat_then_sum (8192, 64) = 0.06879305839538574\n",
      " \n",
      "simple (8192, 128) = 0.016700029373168945\n",
      "batched (8192, 128) = 0.06096982955932617\n",
      "late_concat_batch (8192, 128) = 0.03319430351257324\n",
      "late_concat_stat_then_sum (8192, 128) = 0.04218292236328125\n",
      " \n",
      "simple (8192, 256) = 0.016368865966796875\n",
      "batched (8192, 256) = 0.03654289245605469\n",
      "late_concat_batch (8192, 256) = 0.022185087203979492\n",
      "late_concat_stat_then_sum (8192, 256) = 0.030840158462524414\n",
      " \n",
      "simple (8192, 512) = 0.015909910202026367\n",
      "batched (8192, 512) = 0.02834796905517578\n",
      "late_concat_batch (8192, 512) = 0.021241188049316406\n",
      "late_concat_stat_then_sum (8192, 512) = 0.029721736907958984\n",
      " \n",
      "simple (8192, 1024) = 0.016342878341674805\n",
      "batched (8192, 1024) = 0.023753881454467773\n",
      "late_concat_batch (8192, 1024) = 0.019906997680664062\n",
      "late_concat_stat_then_sum (8192, 1024) = 0.027106761932373047\n",
      " \n",
      " \n",
      "simple (16384, 32) = 0.015403985977172852\n",
      "batched (16384, 32) = 0.12796521186828613\n",
      "late_concat_batch (16384, 32) = 0.03316378593444824\n",
      "late_concat_stat_then_sum (16384, 32) = 0.047714948654174805\n",
      " \n",
      "simple (16384, 64) = 0.015404939651489258\n",
      "batched (16384, 64) = 0.06808018684387207\n",
      "late_concat_batch (16384, 64) = 0.02110910415649414\n",
      "late_concat_stat_then_sum (16384, 64) = 0.035378217697143555\n",
      " \n",
      "simple (16384, 128) = 0.016537189483642578\n",
      "batched (16384, 128) = 0.03887510299682617\n",
      "late_concat_batch (16384, 128) = 0.01675701141357422\n",
      "late_concat_stat_then_sum (16384, 128) = 0.024163246154785156\n",
      " \n",
      "simple (16384, 256) = 0.016155004501342773\n",
      "batched (16384, 256) = 0.02858901023864746\n",
      "late_concat_batch (16384, 256) = 0.018745899200439453\n",
      "late_concat_stat_then_sum (16384, 256) = 0.026553869247436523\n",
      " \n",
      "simple (16384, 512) = 0.016232967376708984\n",
      "batched (16384, 512) = 0.02406597137451172\n",
      "late_concat_batch (16384, 512) = 0.018657684326171875\n",
      "late_concat_stat_then_sum (16384, 512) = 0.027824878692626953\n",
      " \n",
      "simple (16384, 1024) = 0.015651941299438477\n",
      "batched (16384, 1024) = 0.019927978515625\n",
      "late_concat_batch (16384, 1024) = 0.017487764358520508\n",
      "late_concat_stat_then_sum (16384, 1024) = 0.024852991104125977\n"
     ]
    }
   ],
   "source": [
    "unifs = jax.random.uniform(jax.random.PRNGKey(0), (16384, 5, 4))\n",
    "\n",
    "run_keys = list(fncs.keys())\n",
    "for sim_batch_size in [512, 1024, 2048, 4096, 8192, 16384]:\n",
    "    print(\" \")\n",
    "    for grid_batch_size in [32, 64, 128, 256, 512, 1024]:\n",
    "        print(\" \")\n",
    "        for k in range(2):\n",
    "            for run_key in run_keys:\n",
    "                start = time.time()\n",
    "                result = fncs[run_key](unifs, sim_batch_size, grid_batch_size)\n",
    "                if k >= 1:\n",
    "                    print(\n",
    "                        f\"{run_key} ({sim_batch_size}, {grid_batch_size}) = {time.time() - start}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "simple (512, 32) = 0.1613318920135498\n",
      "batched (512, 32) = 2.598283052444458\n",
      "late_concat_batch (512, 32) = 1.108854055404663\n",
      "late_concat_stat_then_sum (512, 32) = 1.1509339809417725\n",
      " \n",
      "simple (512, 64) = 0.17508196830749512\n",
      "batched (512, 64) = 1.4232990741729736\n",
      "late_concat_batch (512, 64) = 0.6891357898712158\n",
      "late_concat_stat_then_sum (512, 64) = 0.7098269462585449\n",
      " \n",
      "simple (512, 128) = 0.1658649444580078\n",
      "batched (512, 128) = 0.8247759342193604\n",
      "late_concat_batch (512, 128) = 0.4614226818084717\n",
      "late_concat_stat_then_sum (512, 128) = 0.48766207695007324\n",
      " \n",
      "simple (512, 256) = 0.17583203315734863\n",
      "batched (512, 256) = 0.5414307117462158\n",
      "late_concat_batch (512, 256) = 0.3533968925476074\n",
      "late_concat_stat_then_sum (512, 256) = 0.36873912811279297\n",
      " \n",
      "simple (512, 512) = 0.2324049472808838\n",
      "batched (512, 512) = 0.39293789863586426\n",
      "late_concat_batch (512, 512) = 0.29862284660339355\n",
      "late_concat_stat_then_sum (512, 512) = 0.3158531188964844\n",
      " \n",
      "simple (512, 1024) = 0.16391801834106445\n",
      "batched (512, 1024) = 0.33527088165283203\n",
      "late_concat_batch (512, 1024) = 0.2652559280395508\n",
      "late_concat_stat_then_sum (512, 1024) = 0.2815268039703369\n",
      " \n",
      " \n",
      "simple (1024, 32) = 0.17309188842773438\n",
      "batched (1024, 32) = 1.4236390590667725\n",
      "late_concat_batch (1024, 32) = 0.6932148933410645\n",
      "late_concat_stat_then_sum (1024, 32) = 0.7435989379882812\n",
      " \n",
      "simple (1024, 64) = 0.19284319877624512\n",
      "batched (1024, 64) = 0.8388590812683105\n",
      "late_concat_batch (1024, 64) = 0.46935296058654785\n",
      "late_concat_stat_then_sum (1024, 64) = 0.4854428768157959\n",
      " \n",
      "simple (1024, 128) = 0.16560888290405273\n",
      "batched (1024, 128) = 0.5397241115570068\n",
      "late_concat_batch (1024, 128) = 0.3560981750488281\n",
      "late_concat_stat_then_sum (1024, 128) = 0.36809206008911133\n",
      " \n",
      "simple (1024, 256) = 0.1609809398651123\n",
      "batched (1024, 256) = 0.39695096015930176\n",
      "late_concat_batch (1024, 256) = 0.29178404808044434\n",
      "late_concat_stat_then_sum (1024, 256) = 0.3121039867401123\n",
      " \n",
      "simple (1024, 512) = 0.1647500991821289\n",
      "batched (1024, 512) = 0.315187931060791\n",
      "late_concat_batch (1024, 512) = 0.2577860355377197\n",
      "late_concat_stat_then_sum (1024, 512) = 0.27268099784851074\n",
      " \n",
      "simple (1024, 1024) = 0.1816272735595703\n",
      "batched (1024, 1024) = 0.2641727924346924\n",
      "late_concat_batch (1024, 1024) = 0.2396707534790039\n",
      "late_concat_stat_then_sum (1024, 1024) = 0.24546098709106445\n",
      " \n",
      " \n",
      "simple (2048, 32) = 0.21064233779907227\n",
      "batched (2048, 32) = 0.8584911823272705\n",
      "late_concat_batch (2048, 32) = 0.4824340343475342\n",
      "late_concat_stat_then_sum (2048, 32) = 0.4986586570739746\n",
      " \n",
      "simple (2048, 64) = 0.17302322387695312\n",
      "batched (2048, 64) = 0.5884957313537598\n",
      "late_concat_batch (2048, 64) = 0.39450907707214355\n",
      "late_concat_stat_then_sum (2048, 64) = 0.38180112838745117\n",
      " \n",
      "simple (2048, 128) = 0.19869303703308105\n",
      "batched (2048, 128) = 0.4045538902282715\n",
      "late_concat_batch (2048, 128) = 0.2989821434020996\n",
      "late_concat_stat_then_sum (2048, 128) = 0.3137071132659912\n",
      " \n",
      "simple (2048, 256) = 0.17336702346801758\n",
      "batched (2048, 256) = 0.3111000061035156\n",
      "late_concat_batch (2048, 256) = 0.264315128326416\n",
      "late_concat_stat_then_sum (2048, 256) = 0.27524900436401367\n",
      " \n",
      "simple (2048, 512) = 0.17420220375061035\n",
      "batched (2048, 512) = 0.260286808013916\n",
      "late_concat_batch (2048, 512) = 0.23772001266479492\n",
      "late_concat_stat_then_sum (2048, 512) = 0.24684381484985352\n",
      " \n",
      "simple (2048, 1024) = 0.18706202507019043\n",
      "batched (2048, 1024) = 0.23654794692993164\n",
      "late_concat_batch (2048, 1024) = 0.22300314903259277\n",
      "late_concat_stat_then_sum (2048, 1024) = 0.2261350154876709\n",
      " \n",
      " \n",
      "simple (4096, 32) = 0.1666698455810547\n",
      "batched (4096, 32) = 0.6105821132659912\n",
      "late_concat_batch (4096, 32) = 0.4177839756011963\n",
      "late_concat_stat_then_sum (4096, 32) = 0.43383097648620605\n",
      " \n",
      "simple (4096, 64) = 0.17563080787658691\n",
      "batched (4096, 64) = 0.43854689598083496\n",
      "late_concat_batch (4096, 64) = 0.31800103187561035\n",
      "late_concat_stat_then_sum (4096, 64) = 0.32314491271972656\n",
      " \n",
      "simple (4096, 128) = 0.1648247241973877\n",
      "batched (4096, 128) = 0.3340170383453369\n",
      "late_concat_batch (4096, 128) = 0.2693047523498535\n",
      "late_concat_stat_then_sum (4096, 128) = 0.29543018341064453\n",
      " \n",
      "simple (4096, 256) = 0.16534781455993652\n",
      "batched (4096, 256) = 0.26557397842407227\n",
      "late_concat_batch (4096, 256) = 0.24414896965026855\n",
      "late_concat_stat_then_sum (4096, 256) = 0.2523469924926758\n",
      " \n",
      "simple (4096, 512) = 0.16181206703186035\n",
      "batched (4096, 512) = 0.23000717163085938\n",
      "late_concat_batch (4096, 512) = 0.22174906730651855\n",
      "late_concat_stat_then_sum (4096, 512) = 0.225754976272583\n",
      " \n",
      "simple (4096, 1024) = 0.16165399551391602\n",
      "batched (4096, 1024) = 0.20556378364562988\n",
      "late_concat_batch (4096, 1024) = 0.20006799697875977\n",
      "late_concat_stat_then_sum (4096, 1024) = 0.20380401611328125\n",
      " \n",
      " \n",
      "simple (8192, 32) = 0.17862296104431152\n",
      "batched (8192, 32) = 0.4755091667175293\n",
      "late_concat_batch (8192, 32) = 0.3392488956451416\n",
      "late_concat_stat_then_sum (8192, 32) = 0.37058496475219727\n",
      " \n",
      "simple (8192, 64) = 0.18544578552246094\n",
      "batched (8192, 64) = 0.34507298469543457\n",
      "late_concat_batch (8192, 64) = 0.2740139961242676\n",
      "late_concat_stat_then_sum (8192, 64) = 0.2955350875854492\n",
      " \n",
      "simple (8192, 128) = 0.20397686958312988\n",
      "batched (8192, 128) = 0.29357218742370605\n",
      "late_concat_batch (8192, 128) = 0.24089503288269043\n",
      "late_concat_stat_then_sum (8192, 128) = 0.2728860378265381\n",
      " \n",
      "simple (8192, 256) = 0.18001079559326172\n",
      "batched (8192, 256) = 0.2373032569885254\n",
      "late_concat_batch (8192, 256) = 0.23225116729736328\n",
      "late_concat_stat_then_sum (8192, 256) = 0.23816704750061035\n",
      " \n",
      "simple (8192, 512) = 0.17287707328796387\n",
      "batched (8192, 512) = 0.19764089584350586\n",
      "late_concat_batch (8192, 512) = 0.19856595993041992\n",
      "late_concat_stat_then_sum (8192, 512) = 0.20550084114074707\n",
      " \n",
      "simple (8192, 1024) = 0.17667794227600098\n",
      "batched (8192, 1024) = 0.18327713012695312\n",
      "late_concat_batch (8192, 1024) = 0.20520401000976562\n",
      "late_concat_stat_then_sum (8192, 1024) = 0.19532060623168945\n",
      " \n",
      " \n",
      "simple (16384, 32) = 0.1671280860900879\n",
      "batched (16384, 32) = 0.39697909355163574\n",
      "late_concat_batch (16384, 32) = 0.27001500129699707\n",
      "late_concat_stat_then_sum (16384, 32) = 0.28826904296875\n",
      " \n",
      "simple (16384, 64) = 0.1718752384185791\n",
      "batched (16384, 64) = 0.311492919921875\n",
      "late_concat_batch (16384, 64) = 0.24412298202514648\n",
      "late_concat_stat_then_sum (16384, 64) = 0.2527658939361572\n",
      " \n",
      "simple (16384, 128) = 0.16422414779663086\n",
      "batched (16384, 128) = 0.2691798210144043\n",
      "late_concat_batch (16384, 128) = 0.2460317611694336\n",
      "late_concat_stat_then_sum (16384, 128) = 0.22274303436279297\n",
      " \n",
      "simple (16384, 256) = 0.22977995872497559\n",
      "batched (16384, 256) = 0.2164781093597412\n",
      "late_concat_batch (16384, 256) = 0.21686315536499023\n",
      "late_concat_stat_then_sum (16384, 256) = 0.22987794876098633\n",
      " \n",
      "simple (16384, 512) = 0.17707300186157227\n",
      "batched (16384, 512) = 0.18654894828796387\n",
      "late_concat_batch (16384, 512) = 0.18823003768920898\n",
      "late_concat_stat_then_sum (16384, 512) = 0.1830918788909912\n",
      " \n",
      "simple (16384, 1024) = 0.171586275100708\n",
      "batched (16384, 1024) = 0.18750977516174316\n",
      "late_concat_batch (16384, 1024) = 0.1825101375579834\n",
      "late_concat_stat_then_sum (16384, 1024) = 0.18258118629455566\n"
     ]
    }
   ],
   "source": [
    "unifs = jax.random.uniform(jax.random.PRNGKey(0), (16384, 31, 4))\n",
    "\n",
    "run_keys = list(fncs.keys())\n",
    "for sim_batch_size in [512, 1024, 2048, 4096, 8192, 16384]:\n",
    "    print(\" \")\n",
    "    for grid_batch_size in [32, 64, 128, 256, 512, 1024]:\n",
    "        print(\" \")\n",
    "        for k in range(2):\n",
    "            for run_key in run_keys:\n",
    "                start = time.time()\n",
    "                result = fncs[run_key](unifs, sim_batch_size, grid_batch_size)\n",
    "                if k >= 1:\n",
    "                    print(\n",
    "                        f\"{run_key} ({sim_batch_size}, {grid_batch_size}) = {time.time() - start}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.354657888412476\n",
      " \n",
      " \n",
      "batched (2048, 128) = 5.971358776092529\n",
      "late_concat_batch (2048, 128) = 5.846956014633179\n",
      "late_concat_stat_then_sum (2048, 128) = 5.888359069824219\n",
      " \n",
      "batched (2048, 256) = 5.758255958557129\n",
      "late_concat_batch (2048, 256) = 5.703609943389893\n",
      "late_concat_stat_then_sum (2048, 256) = 5.749382972717285\n",
      " \n",
      "batched (2048, 512) = 5.766067028045654\n",
      "late_concat_batch (2048, 512) = 5.766237020492554\n",
      "late_concat_stat_then_sum (2048, 512) = 5.792371034622192\n",
      " \n",
      "batched (2048, 1024) = 6.105571746826172\n",
      "late_concat_batch (2048, 1024) = 5.968732833862305\n",
      "late_concat_stat_then_sum (2048, 1024) = 6.047160625457764\n",
      " \n",
      " \n",
      "batched (4096, 128) = 5.980096817016602\n",
      "late_concat_batch (4096, 128) = 5.837982177734375\n",
      "late_concat_stat_then_sum (4096, 128) = 5.808861970901489\n",
      " \n",
      "batched (4096, 256) = 5.766739368438721\n",
      "late_concat_batch (4096, 256) = 5.745783090591431\n",
      "late_concat_stat_then_sum (4096, 256) = 5.784740924835205\n",
      " \n",
      "batched (4096, 512) = 6.136857986450195\n",
      "late_concat_batch (4096, 512) = 6.076946258544922\n",
      "late_concat_stat_then_sum (4096, 512) = 6.122919797897339\n",
      " \n",
      "batched (4096, 1024) = 6.266105890274048\n",
      "late_concat_batch (4096, 1024) = 6.322642087936401\n",
      "late_concat_stat_then_sum (4096, 1024) = 6.323745012283325\n",
      " \n",
      " \n",
      "batched (8192, 128) = 5.92331600189209\n",
      "late_concat_batch (8192, 128) = 5.866394758224487\n",
      "late_concat_stat_then_sum (8192, 128) = 5.870597839355469\n",
      " \n",
      "batched (8192, 256) = 6.204341888427734\n",
      "late_concat_batch (8192, 256) = 6.160974025726318\n",
      "late_concat_stat_then_sum (8192, 256) = 6.125115156173706\n",
      " \n",
      "batched (8192, 512) = 6.3572211265563965\n",
      "late_concat_batch (8192, 512) = 6.376079082489014\n",
      "late_concat_stat_then_sum (8192, 512) = 6.34675407409668\n",
      " \n",
      "batched (8192, 1024) = 6.377340078353882\n",
      "late_concat_batch (8192, 1024) = 6.461400747299194\n",
      "late_concat_stat_then_sum (8192, 1024) = 6.491009950637817\n",
      " \n",
      " \n",
      "batched (16384, 128) = 6.044701337814331\n",
      "late_concat_batch (16384, 128) = 5.964847087860107\n",
      "late_concat_stat_then_sum (16384, 128) = 5.978416204452515\n",
      " \n",
      "batched (16384, 256) = 6.3167290687561035\n",
      "late_concat_batch (16384, 256) = 6.30471396446228\n",
      "late_concat_stat_then_sum (16384, 256) = 6.359824180603027\n",
      " \n",
      "batched (16384, 512) = 6.495150089263916\n",
      "late_concat_batch (16384, 512) = 8.138368129730225\n",
      "late_concat_stat_then_sum (16384, 512) = 8.009371757507324\n",
      " \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [128], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m run_key \u001b[39min\u001b[39;00m run_keys:\n\u001b[1;32m     16\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 17\u001b[0m     result \u001b[39m=\u001b[39m fncs[run_key](unifs, sim_batch_size, grid_batch_size)\n\u001b[1;32m     18\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     19\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m     20\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrun_key\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00msim_batch_size\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mgrid_batch_size\u001b[39m}\u001b[39;00m\u001b[39m) = \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m         )\n",
      "Cell \u001b[0;32mIn [120], line 30\u001b[0m, in \u001b[0;36mlate_concat_batch\u001b[0;34m(unifs_chunk, sim_batch_size, grid_batch_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m         j_end \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(theta\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], j \u001b[39m+\u001b[39m grid_batch_size)\n\u001b[1;32m     28\u001b[0m         subunifs_chunk \u001b[39m=\u001b[39m unifs_chunk[i_begin:i_end]\n\u001b[1;32m     29\u001b[0m         rejs\u001b[39m.\u001b[39mappend(\n\u001b[0;32m---> 30\u001b[0m             stat_sum(\n\u001b[1;32m     31\u001b[0m                 lam,\n\u001b[1;32m     32\u001b[0m                 theta[j_begin:j_end],\n\u001b[1;32m     33\u001b[0m                 null_truth[j_begin:j_end],\n\u001b[1;32m     34\u001b[0m                 subunifs_chunk,\n\u001b[1;32m     35\u001b[0m             )\n\u001b[1;32m     36\u001b[0m         )\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mconcatenate(rejs)\u001b[39m.\u001b[39mblock_until_ready()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unifs = jax.random.uniform(jax.random.PRNGKey(0), (16384, 150, 4))\n",
    "\n",
    "fncs[\"simple\"](unifs, 1, 1)\n",
    "\n",
    "start = time.time()\n",
    "fncs[\"simple\"](unifs, 1, 1)\n",
    "print(time.time() - start)\n",
    "\n",
    "run_keys = [\"batched\", \"late_concat_batch\", \"late_concat_stat_then_sum\"]\n",
    "for sim_batch_size in [2048, 4096, 8192, 16384]:\n",
    "    print(\" \")\n",
    "    for grid_batch_size in [128, 256, 512, 1024]:\n",
    "        print(\" \")\n",
    "        for k in range(2):\n",
    "            for run_key in run_keys:\n",
    "                start = time.time()\n",
    "                result = fncs[run_key](unifs, sim_batch_size, grid_batch_size)\n",
    "                if k >= 1:\n",
    "                    print(\n",
    "                        f\"{run_key} ({sim_batch_size}, {grid_batch_size}) = {time.time() - start}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "batched (256, 32) = 14.0449538230896\n",
      "late_concat_batch (256, 32) = 11.150763988494873\n",
      "late_concat_stat_then_sum (256, 32) = 11.255561113357544\n",
      " \n",
      "batched (256, 64) = 8.600068092346191\n",
      "late_concat_batch (256, 64) = 7.188723087310791\n",
      "late_concat_stat_then_sum (256, 64) = 7.206992864608765\n",
      " \n",
      "batched (256, 128) = 6.206650972366333\n",
      "late_concat_batch (256, 128) = 5.513365983963013\n",
      "late_concat_stat_then_sum (256, 128) = 5.526437044143677\n",
      " \n",
      "batched (256, 256) = 5.517500162124634\n",
      "late_concat_batch (256, 256) = 5.2202980518341064\n",
      "late_concat_stat_then_sum (256, 256) = 5.21939492225647\n",
      " \n",
      " \n",
      "batched (512, 32) = 8.675849914550781\n",
      "late_concat_batch (512, 32) = 7.147514820098877\n",
      "late_concat_stat_then_sum (512, 32) = 7.215574026107788\n",
      " \n",
      "batched (512, 64) = 6.239650011062622\n",
      "late_concat_batch (512, 64) = 5.512767314910889\n",
      "late_concat_stat_then_sum (512, 64) = 5.5762341022491455\n",
      " \n",
      "batched (512, 128) = 5.552695035934448\n",
      "late_concat_batch (512, 128) = 5.230609893798828\n",
      "late_concat_stat_then_sum (512, 128) = 5.276835918426514\n",
      " \n",
      "batched (512, 256) = 5.877730846405029\n",
      "late_concat_batch (512, 256) = 5.689897060394287\n",
      "late_concat_stat_then_sum (512, 256) = 5.745021820068359\n",
      " \n",
      " \n",
      "batched (1024, 32) = 6.484601020812988\n",
      "late_concat_batch (1024, 32) = 5.563495874404907\n",
      "late_concat_stat_then_sum (1024, 32) = 5.64278769493103\n",
      " \n",
      "batched (1024, 64) = 5.648755073547363\n",
      "late_concat_batch (1024, 64) = 5.226381063461304\n",
      "late_concat_stat_then_sum (1024, 64) = 5.327516794204712\n",
      " \n",
      "batched (1024, 128) = 5.955430269241333\n",
      "late_concat_batch (1024, 128) = 5.810141086578369\n",
      "late_concat_stat_then_sum (1024, 128) = 5.844859838485718\n",
      " \n",
      "batched (1024, 256) = 5.734298944473267\n",
      "late_concat_batch (1024, 256) = 5.656989336013794\n",
      "late_concat_stat_then_sum (1024, 256) = 5.703695058822632\n"
     ]
    }
   ],
   "source": [
    "unifs = jax.random.uniform(jax.random.PRNGKey(0), (16384, 150, 4))\n",
    "\n",
    "run_keys = [\"batched\", \"late_concat_batch\", \"late_concat_stat_then_sum\"]\n",
    "for sim_batch_size in [256, 512, 1024]:\n",
    "    print(\" \")\n",
    "    for grid_batch_size in [32, 64, 128, 256]:\n",
    "        print(\" \")\n",
    "        for k in range(2):\n",
    "            for run_key in run_keys:\n",
    "                start = time.time()\n",
    "                result = fncs[run_key](unifs, sim_batch_size, grid_batch_size)\n",
    "                if k >= 1:\n",
    "                    print(\n",
    "                        f\"{run_key} ({sim_batch_size}, {grid_batch_size}) = {time.time() - start}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('confirm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4c6ec5b2d6c7b38df115d547b82cd53ca25eea58d87299956d35a9dc79f19f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
