{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore importance sampling on some trivial test cases.\n",
    "\n",
    "The steps of importance sampling are described in the overleaf, Appendix D.\n",
    "\n",
    "We will implement them first for the 1-dimensional z-test, then the 2- and 3-dimensional z-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas \n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.linspace(-2, 2, 11)\n",
    "z = np.random.normal(0, 1, 1000)\n",
    "data = mu[None,:] + z[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data =  data.flatten()\n",
    "#Now, we select the rejections in order to run k-means on them\n",
    "selection = flat_data > 1.96\n",
    "rejections = flat_data[selection]\n",
    "standardized_rejections = (rejections - np.mean(rejections))/np.std(rejections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "kmeans= KMeans(n_clusters=n_clusters,\n",
    "               init = \"random\",\n",
    "            n_init=10,\n",
    "               max_iter=300,\n",
    "               random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(init=&#x27;random&#x27;, n_clusters=5, n_init=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(init=&#x27;random&#x27;, n_clusters=5, n_init=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(init='random', n_clusters=5, n_init=10, random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(rejections.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.15110038],\n",
       "       [3.52505375],\n",
       "       [4.34462706],\n",
       "       [2.5527284 ],\n",
       "       [2.99012636]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_cluster_centers = kmeans.cluster_centers_\n",
    "mu_cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1,  2,  3,  4], dtype=int32),\n",
       " array([9649,  513,  151,   43,  383,  261]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_orig = len(flat_data)\n",
    "flat_labels = np.full(n_orig, -1,dtype = np.int32)\n",
    "flat_labels[selection] = kmeans.labels_\n",
    "np.unique(flat_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = flat_labels.reshape(data.shape)\n",
    "n_sims_per_theta = data.shape[0] # 1000 for now\n",
    "n_theta = data.shape[1] # 11 for now\n",
    "target_fraction = np.full((n_clusters + 1, n_theta),-1)\n",
    "labelset = np.unique(labels)\n",
    "labelbins = np.append(labelset - 0.5,n_clusters - 0.5)\n",
    "for i in range(n_theta):\n",
    "    target_fraction[:,i] = np.histogram(labels[:,i], bins = labelbins)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1000,  999,  999,  996,  992,  973,  938,  874,  770,  635,  473],\n",
       "       [   0,    1,    0,    3,    4,   18,   34,   62,  100,  130,  161],\n",
       "       [   0,    0,    0,    0,    1,    1,    3,    6,   17,   41,   82],\n",
       "       [   0,    0,    0,    0,    0,    0,    1,    1,    4,    9,   28],\n",
       "       [   0,    0,    1,    0,    3,    5,   20,   37,   68,  110,  139],\n",
       "       [   0,    0,    0,    1,    0,    3,    4,   20,   41,   75,  117]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_fraction\n",
    "# looks good so far!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get into the business of doing the importance samples and re-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we construct the weights matrix: how many sims are we planning for each value of theta?\n",
    "n_per_thetaj = 1000\n",
    "# We want this to net out to, let's say, 1% of the total weight...\n",
    "sum_rejects = np.delete(target_fraction, 0, axis = 0)\n",
    "any_successes = np.sum(sum_rejects, axis = 0) > 0\n",
    "relevant_mu = mu[any_successes]\n",
    "any_successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = sum_rejects / np.maximum(np.sum(sum_rejects,axis = 0)[None,:], 1)\n",
    "wjj = 0.01\n",
    "important_weights = temp[:,any_successes]*(1 - wjj)\n",
    "important_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10,), (5, 10)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[relevant_mu.shape , important_weights.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(np.full_like(relevant_mu,wjj)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_weights = np.append(np.diag(np.full_like(relevant_mu,wjj)), important_weights, axis = 0)\n",
    "np.sum(full_weights, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we do the importance samples:\n",
    "mu_importance = np.append(relevant_mu,mu_cluster_centers)\n",
    "z_importance = np.random.normal(0, 1, size = 1000 * len(mu_importance)).reshape(1000, len(mu_importance))\n",
    "data_importance = mu_importance[None,:] + z_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 15), (15,), (10,), (10, 15))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_importance.shape, mu_importance.shape, relevant_mu.shape, np.transpose(full_weights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixture_ratio(j, X_ik, wj, mus):\n",
    "    muj = mus[j]\n",
    "    ratio = jnp.exp((mus - muj) * X_ik - 0.5 * (mus ** 2 - muj ** 2))\n",
    "    return wj @ ratio\n",
    "\n",
    "def average_rej(j, rejs, X_k, wj, mus):\n",
    "    mr_vm = jax.vmap(mixture_ratio, in_axes=(None, 0, None, None))\n",
    "    return jnp.mean(rejs / mr_vm(j, X_k, wj, mus))\n",
    "\n",
    "def imp_est_j(j, rejs, X, wj, mus):\n",
    "    avg_rej_vm = jax.vmap(average_rej, in_axes=(None, 0, 0, None, None))\n",
    "    return wj @ avg_rej_vm(j, rejs, X, wj, mus)\n",
    "\n",
    "@jax.jit\n",
    "def imp_est(rejs, X, ws, mus):\n",
    "    idx = jnp.arange(0, ws.shape[0])\n",
    "    return jax.vmap(imp_est_j, in_axes=(0, None, None, 0, None))(\n",
    "        idx, rejs, X, ws, mus\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.8215892e-04, 7.9667533e-04, 2.8277736e-03, 9.1251247e-03,\n",
       "       2.4826376e-02, 5.9318118e-02, 1.2270814e-01, 2.2361267e-01,\n",
       "       3.5971874e-01, 5.1689267e-01], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_importance.T\n",
    "rejs = X > 1.96\n",
    "ws = full_weights.T\n",
    "mus = mu_importance\n",
    "imp_est(rejs, X, ws, mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensions: i (simulations), j (initial theta), k (importance theta which generates samples), m (second dummy copy of importance theta)\n",
    "inside_exponent = data_importance[:,None,:, None]*(mu_importance[None,None,None, :] - relevant_mu[None,:,None, None]) - mu_importance[None,None,None,:]**2/2 + relevant_mu[None,:,None, None]**2/2\n",
    "likelihood_ratios = np.exp(inside_exponent) # I bet this is the problem! Look in this line and the above for a bug!\n",
    "denoms = np.sum(likelihood_ratios * np.transpose(full_weights)[None, :, None, :], axis = 3)\n",
    "rejects = data_importance > 1.96\n",
    "inner_mean = np.mean(rejects[:,None,:]/denoms, axis = 0) #this is the inner sum divided by n_j\n",
    "inner_mse_estimate = np.mean((rejects[:,None,:]/denoms)**2, axis = 0) - inner_mean**2 # trying to do an empirical calculation of the variance of each obs\n",
    "final_result = np.sum(inner_mean * np.transpose(full_weights), axis = 1)\n",
    "final_variance_estimate =np.sum((inner_mse_estimate/1000) * (np.transpose(full_weights)**2), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.82158972e-04, 7.96675437e-04, 2.82777322e-03, 9.12512642e-03,\n",
       "       2.48263719e-02, 5.93181096e-02, 1.22708153e-01, 2.23612629e-01,\n",
       "       3.59718700e-01, 5.16892710e-01])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.33535664e-10, 2.55633023e-09, 1.81151078e-08, 1.07858147e-07,\n",
       "       7.71020676e-07, 3.06608957e-06, 9.18504517e-06, 2.13519917e-05,\n",
       "       3.64442843e-05, 4.88504788e-05])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_variance_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1363.8737789 ,  311.39980869,  155.65885344,   83.83102044,\n",
       "         31.39996616,   18.19890459,   11.72023219,    8.1308584 ,\n",
       "          6.3198156 ,    5.11181553])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#estimated sample size ratio\n",
    "((final_result * (1-final_result)) / (1000)) /final_variance_estimate\n",
    "# EXCELLENT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6       , -1.2       , -0.8       , -0.4       ,  0.        ,\n",
       "        0.4       ,  0.8       ,  1.2       ,  1.6       ,  2.        ,\n",
       "        2.15110038,  3.52505375,  4.34462706,  2.5527284 ,  2.99012636])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denominator formula:\n",
    "\n",
    "denom = sum w_jk Pk/Pj (X).\n",
    "\n",
    "The likelihood ratio is exp([x -\\ mu_j]^2/2 - [x-\\mu_k]^2/2) = exp(-mu_k^2/2 + mu_j^2/2 + x(mu_k - mu_j))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generalize this to two-dimensional mu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.linspace(-2, 2, 11)\n",
    "z = np.random.normal(0, 1, 1000)\n",
    "data = mu[None,:] + z[:,None]\n",
    "flat_data =  data.flatten()\n",
    "#Now, we select the rejections in order to run k-means on them\n",
    "selection = flat_data > 1.96\n",
    "rejections = flat_data[selection]\n",
    "standardized_rejections = (rejections - np.mean(rejections))/np.std(rejections)\n",
    "n_clusters = 5\n",
    "kmeans= KMeans(n_clusters=n_clusters,\n",
    "               init = \"random\",\n",
    "            n_init=10,\n",
    "               max_iter=300,\n",
    "               random_state = 42)\n",
    "kmeans.fit(standardized_rejections.reshape(-1,1))\n",
    "mu_cluster_centers = kmeans.cluster_centers_ * np.std(rejections) + np.mean(rejections)\n",
    "kmeans.labels_\n",
    "n_orig = len(flat_data)\n",
    "flat_labels = np.full(n_orig, -1,dtype = np.int32)\n",
    "flat_labels[selection] = kmeans.labels_\n",
    "labels = flat_labels.reshape(data.shape)\n",
    "n_sims_per_theta = data.shape[0] # 1000 for now\n",
    "n_theta = data.shape[1] # 11 for now\n",
    "target_fraction = np.full((n_clusters + 1, n_theta),-1)\n",
    "labelset = np.unique(labels)\n",
    "labelbins = np.append(labelset - 0.5,n_clusters - 0.5)\n",
    "for i in range(n_theta):\n",
    "    target_fraction[:,i] = np.histogram(labels[:,i], bins = labelbins)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pilot sims done, now the real run:\n",
    "n_per_thetaj = 1000\n",
    "# We want this to net out to, let's say, 1% of the total weight...\n",
    "sum_rejects = np.delete(target_fraction, 0, axis = 0)\n",
    "any_successes = np.sum(sum_rejects, axis = 0) > 0\n",
    "any_successes\n",
    "relevant_mu = mu[any_successes]\n",
    "temp = sum_rejects / np.sum(sum_rejects,axis = 0)[None,:]\n",
    "wjj = 0.01\n",
    "important_weights = temp[:,any_successes]*(1 - wjj)\n",
    "full_weights = np.append(np.diag(np.full_like(relevant_mu,wjj)), important_weights, axis = 0)\n",
    "# Now we do the importance samples:\n",
    "mu_importance = np.append(relevant_mu,mu_cluster_centers)\n",
    "z_importance = np.random.normal(0, 1, size = 1000 * len(mu_importance)).reshape(1000, len(mu_importance))\n",
    "data_importance = mu_importance[None,:] + z_importance\n",
    "inside_exponent = data_importance[:,None,:, None]*(mu_importance[None,None,None, :] - relevant_mu[None,:,None, None]) - mu_importance[None,None,None,:]**2/2 + relevant_mu[None,:,None, None]**2/2\n",
    "likelihood_ratios = np.exp(inside_exponent) # I bet this is the problem! Look in this line and the above for a bug!\n",
    "denoms = np.sum(likelihood_ratios * np.transpose(full_weights)[None, :, None, :], axis = 3)\n",
    "rejects = data_importance > 1.96\n",
    "inner_mean = np.mean(rejects[:,None,:]/denoms, axis = 0) #this is the inner sum divided by n_j\n",
    "inner_mse_estimate = np.mean((rejects[:,None,:]/denoms)**2, axis = 0) - inner_mean**2 # trying to do an empirical calculation of the variance of each obs\n",
    "final_result = np.sum(inner_mean * np.transpose(full_weights), axis = 1)\n",
    "final_variance_estimate =np.sum((inner_mse_estimate/1000) * (np.transpose(full_weights)**2), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confirm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d574717a19d12573763700bcd6833eaae2108879723021a1c549979ef70be90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
