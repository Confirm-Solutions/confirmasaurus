```python
import imprint.nb_util as nb_util
nb_util.setup_nb()

import time
import jax
import jax.numpy as jnp
from jax.scipy.special import expit, logit
import numpy as np
import matplotlib.pyplot as plt

import confirm.models.wd41 as wd41
import imprint as ip
```

## Exploring

We have two subgroups, each split equally into treatment and control arms:
- $p_{\mathrm{TNBC}}^{c}$ - TNBC subgroup control arm effectiveness.
- $p_{\mathrm{TNBC}}^{t}$ - TNBC subgroup treatment arm effectiveness.
- $p_{\mathrm{HR+}}^{c}$ - HR+ subgroup control arm effectiveness.
- $p_{\mathrm{HR+}}^{t}$ - HR+ subgroup treatment arm effectiveness.
  
$f_{\mathrm{TNBC}}$ is the fraction of patients in the TNBC subgroup.

The null hypotheses here are:

$$
p_{\mathrm{TNBC}}^{c} > p_{\mathrm{TNBC}}^{t}
$$

$$
f_{\mathrm{TNBC}} p_{\mathrm{TNBC}}^{c} + (1 - f_{\mathrm{TNBC}}) p_{\mathrm{HR+}}^{c} > 
f_{\mathrm{TNBC}} p_{\mathrm{TNBC}}^{t} + (1 - f_{\mathrm{TNBC}}) p_{\mathrm{HR+}}^{t}
$$

```python
theta_tnbc_c = -1
p_tnbc_c = expit(theta_tnbc_c)
theta_hrplus_c = -1
p_hrplus_c = expit(theta_hrplus_c)


def get_theta(theta):
    t_tnbc_t = theta[..., 0]
    return jnp.stack(
        (
            jnp.full_like(t_tnbc_t, theta_tnbc_c),
            t_tnbc_t,
            jnp.full_like(t_tnbc_t, theta_hrplus_c),
            theta[..., 1],
        ),
        axis=-1,
    )


class WD41Null2D(wd41.WD41Null):
    def get_theta(self, theta):
        return get_theta(theta)


class WD412D(wd41.WD41):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.family_params = {
            "n": jnp.array(
                [
                    self.n_max_tnbc,
                    self.n_max_hrplus,
                ]
            )
        }

    def sim_batch(
        self,
        begin_sim: int,
        end_sim: int,
        theta: jnp.ndarray,
        null_truth: jnp.ndarray,
        detailed: bool = False,
    ):
        return super().sim_batch(
            begin_sim,
            end_sim,
            get_theta(theta),
            null_truth,
            detailed,
        )


model = WD412D(0, 1)
nulls = [ip.hypo("-1 > theta0"), WD41Null2D(model.true_frac_tnbc)]

grid = ip.cartesian_grid([-2.5, -2.5], [-0.0, -0.0], n=[90, 90], null_hypos=nulls)

```

```python
val_df = ip.validate(WD412D, g=grid, lam=0.025, K=10000)
```

```python
theta = grid.get_theta()
p = expit(theta)
f = model.true_frac_tnbc
ptt = expit(np.linspace(-2.5, theta[:,1].max(), 100))
pht = ((p_tnbc_c * f + p_hrplus_c * (1 - f)) - (ptt * f)) / (1 - f)
```

```python
plt.scatter(theta[:,0], theta[:,1], c=val_df['tie_est'], s=8)
plt.axvline(theta_tnbc_c, color='red', linewidth=4)
plt.plot(logit(ptt), logit(pht), color='red', linewidth=4)
cbar = plt.colorbar()
cbar.set_label('$\hat{f}$')
plt.xlabel(r'$\theta_{TNBC}^{T}$')
plt.ylabel(r'$\theta_{HR+}^{T}$')
plt.xlim([-2.5, 0.0])
plt.ylim([-2.5, 0.0])
plt.show()
```

```python
cal_df = ip.calibrate(WD412D, g=grid, alpha=0.025, K=10000)
```

```python
plt.scatter(theta[:,0], theta[:,1], c=cal_df['lams'], s=8, vmin=0, vmax=0.05)
plt.axvline(theta_tnbc_c, color='red', linewidth=4)
plt.plot(logit(ptt), logit(pht), color='red', linewidth=4)
cbar = plt.colorbar()
cbar.set_label('$\lambda^{*}$')
plt.xlabel(r'$\theta_{TNBC}^{T}$')
plt.ylabel(r'$\theta_{HR+}^{T}$')
plt.xlim([-2.5, 0.0])
plt.ylim([-2.5, 0.0])
plt.title('$\lambda^{**}='+f'{cal_df["lams"].min():.4f}$')
plt.show()
```

## Bigger job

```python
from confirm.adagrid import ada_calibrate
```

```python
grid = ip.cartesian_grid(
    [-2.5, -2.5],
    [1.0, 1.0],
    n=[10, 10],
    null_hypos = nulls
)
```

```python
db = ada_calibrate(
    WD412D,
    db=db,
    alpha=0.025,
    bias_target=0.0005,
    grid_target=0.0005,
    std_target=0.0015,
    calibration_min_idx=80,
    step_size=2**13,
    packet_size=2**12,
    overrides=dict(
        bias_target=0.0005,
        grid_target=0.0005,
        std_target=0.0015
    )
)
```

```python
g_r = ip.grid.Grid(db.get_results(), None).prune_inactive()
```

```python
g_r.n_tiles
```

```python
B_lams = np.array([g_r.df[f'B_lams{i}'].min() for i in range(50)])
lamss = g_r.df['lams'].min()
B_lams, lamss, lamss - B_lams.mean()
```

```python

plt.hist(B_lams)
plt.axvline(lamss, color='r')
plt.show()
```

```python
ordering = g_r.df['orderer'].sort_values()
ordering
```

```python
plt.plot(ordering.values)
plt.ylim([0.022, 0.026])
plt.show()
```

```python
worst_tile = g_r.df.loc[g_r.df['lams'].idxmin()]
worst_tile[['theta0', 'theta1', 'radii0', 'radii1', 'orderer', "alpha0", 'K', 'lams']]
```

```python
np.searchsorted(ordering, worst_tile['orderer']), ordering.shape
```

```python
B_worst_tile = [g_r.df.loc[g_r.df[f'B_lams{i}'].idxmin()] for i in range(50)]
[(B_worst_tile[i]['orderer'], np.searchsorted(ordering, B_worst_tile[i]['orderer'])) for i in range(50)]
```

```python
theta = g_r.get_theta()
p = expit(theta)
f = model.true_frac_tnbc
ptt = expit(np.linspace(-2.5, theta[:,1].max(), 100))
pht = ((p[0, 0] * f + p[0, 2] * (1 - f)) - (ptt * f)) / (1 - f)
plt.scatter(theta[:,0], theta[:,1], c=g_r.df['lams'], s=2, vmin=0.02, vmax=0.05)
plt.axvline(theta_tnbc_c, color='red', linewidth=4)
plt.plot(logit(ptt), logit(pht), color='red', linewidth=4)
cbar = plt.colorbar()
cbar.set_label('$\lambda^{*}$')
plt.xlabel(r'$\theta_{TNBC}^{T}$')
plt.ylabel(r'$\theta_{HR+}^{T}$')
plt.xlim([-2.5, 0.0])
plt.ylim([-2.5, 0.0])
plt.title('$\lambda^{**}='+f'{lamss:.4f}$')
plt.show()
```
