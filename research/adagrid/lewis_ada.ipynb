{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a35c87",
   "metadata": {},
   "source": [
    "Tuning inside Adagrid is a scary thing to do. This document is a summary of the various problems I've run into. \n",
    "\n",
    "First, some basics. We have three different groups of thresholds. $i$ is a tile index, $j$ is a bootstrap index.\n",
    "1. The original sample, $\\lambda^*_i$ and it's grid-wise minimum $\\lambda^{**}$. \n",
    "2. $N_B$  global bootstraps $\\lambda_{i, B_j}^*$ and their grid-wise minima $\\lambda_{B_j}^{**}$. In the code, info regarding these bootstraps is prefixed with `B_`.\n",
    "3. $N_b$  tile-wise investigation bootstraps $\\lambda_{i, b_j}^*$ and their tile-wise minima $\\lambda_{i}^{**}$. In the code, info regarding these bootstraps is prefixed with `twb_` standing for \"tile-wise bootstrap\". \n",
    "\n",
    "For each of these tuning problems, we tune at TIE level $\\alpha_0 = \\alpha - C_{\\alpha}$ where $C_{\\alpha}$ is the TIE consumed by continuous simulation extension. The C stands for \"cost\" and in the code this is called `alpha_cost`. \n",
    "\n",
    "The different problems I've run into so far:\n",
    "- impossible tuning. This occurs when $\\alpha_0 < 2 / (K+1)$ . In this situation, we can't tune because there are too few test statistics. We need to either run more simulations (increase $K$) or refine (increase $\\alpha_0$). \n",
    "- it's possible to have a tile where the twb_min_lam is large... like 1 but B_lam is small like 0.015. \n",
    "\t- these tiles have too much variance, but there's no way to detect them because our tilewise bootstrap didn't turn up any evidence of danger. \n",
    "\t- it's not possible to completely remove this possibility because there's always some randomness.\n",
    "\t- this partially suggests i'm using a baseline of too few simulations or too large tiles. this is fixable. I bumped up the baseline K to 4096.\n",
    "\t- another option would be to use a new bootstrap in some way to get a new sample?\n",
    "- part of the problem is tiles for which $\\alpha_0$ is super small and so the tuning result is like index 2 of the batch which will of course result in a high variance. the simple thing to do is to make $\\alpha_0$ larger. is there a smooth way to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def6611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import confirm.outlaw.nb_util as nb_util\n",
    "\n",
    "nb_util.setup_nb(pretty=True)\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "import time\n",
    "import jax\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import scipy.spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from confirm.mini_imprint import grid\n",
    "from confirm.lewislib import grid as lewgrid\n",
    "from confirm.lewislib import lewis, batch\n",
    "from confirm.mini_imprint import binomial, checkpoint\n",
    "\n",
    "import confirm.mini_imprint.lewis_drivers as lts\n",
    "\n",
    "from rich import print as rprint\n",
    "\n",
    "# Configuration used during simulation\n",
    "name = \"4d_full\"\n",
    "params = {\n",
    "    \"n_arms\": 4,\n",
    "    \"n_stage_1\": 50,\n",
    "    \"n_stage_2\": 100,\n",
    "    \"n_stage_1_interims\": 2,\n",
    "    \"n_stage_1_add_per_interim\": 100,\n",
    "    \"n_stage_2_add_per_interim\": 100,\n",
    "    \"stage_1_futility_threshold\": 0.15,\n",
    "    \"stage_1_efficacy_threshold\": 0.7,\n",
    "    \"stage_2_futility_threshold\": 0.2,\n",
    "    \"stage_2_efficacy_threshold\": 0.95,\n",
    "    \"inter_stage_futility_threshold\": 0.6,\n",
    "    \"posterior_difference_threshold\": 0,\n",
    "    \"rejection_threshold\": 0.05,\n",
    "    \"key\": jax.random.PRNGKey(0),\n",
    "    \"n_table_pts\": 20,\n",
    "    \"n_pr_sims\": 100,\n",
    "    \"n_sig2_sims\": 20,\n",
    "    \"batch_size\": int(2**12),\n",
    "    \"cache_tables\": f\"./{name}/lei_cache.pkl\",\n",
    "}\n",
    "\n",
    "# Configuration used during simulation\n",
    "# name = \"3d_smaller2\"\n",
    "# params = {\n",
    "#     \"n_arms\": 3,\n",
    "#     \"n_stage_1\": 50,\n",
    "#     \"n_stage_2\": 100,\n",
    "#     \"n_stage_1_interims\": 2,\n",
    "#     \"n_stage_1_add_per_interim\": 100,\n",
    "#     \"n_stage_2_add_per_interim\": 100,\n",
    "#     \"stage_1_futility_threshold\": 0.15,\n",
    "#     \"stage_1_efficacy_threshold\": 0.7,\n",
    "#     \"stage_2_futility_threshold\": 0.2,\n",
    "#     \"stage_2_efficacy_threshold\": 0.95,\n",
    "#     \"inter_stage_futility_threshold\": 0.6,\n",
    "#     \"posterior_difference_threshold\": 0,\n",
    "#     \"rejection_threshold\": 0.05,\n",
    "#     \"key\": jax.random.PRNGKey(0),\n",
    "#     \"n_table_pts\": 20,\n",
    "#     \"n_pr_sims\": 100,\n",
    "#     \"n_sig2_sims\": 20,\n",
    "#     \"batch_size\": int(2**12),\n",
    "#     \"cache_tables\": f\"./{name}/lei_cache.pkl\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2320d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_arms = params[\"n_arms\"]\n",
    "ns = np.concatenate(\n",
    "    [np.ones(n_arms - 1)[:, None], -np.eye(n_arms - 1)],\n",
    "    axis=-1,\n",
    ")\n",
    "null_hypos = [grid.HyperPlane(n, 0) for n in ns]\n",
    "symmetry = []\n",
    "for i in range(n_arms - 2):\n",
    "    n = np.zeros(n_arms)\n",
    "    n[i + 1] = 1\n",
    "    n[i + 2] = -1\n",
    "    symmetry.append(grid.HyperPlane(n, 0))\n",
    "\n",
    "theta_min = -1.0\n",
    "theta_max = 1.0\n",
    "init_grid_size = 8\n",
    "theta, radii = grid.cartesian_gridpts(\n",
    "    np.full(n_arms, theta_min),\n",
    "    np.full(n_arms, theta_max),\n",
    "    np.full(n_arms, init_grid_size),\n",
    ")\n",
    "g_raw = grid.build_grid(theta, radii)\n",
    "g = grid.build_grid(\n",
    "    theta, radii, null_hypos=null_hypos, symmetry_planes=symmetry, should_prune=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9f1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adastate\n",
    "from criterion import Criterion\n",
    "\n",
    "lei_obj = lewis.Lewis45(**params)\n",
    "n_arm_samples = int(lei_obj.unifs_shape()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565d6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = adastate.AdaParams(\n",
    "#     init_K=2**11,\n",
    "#     n_K_double=8,\n",
    "#     alpha_target=0.025,\n",
    "#     grid_target=0.002,\n",
    "#     bias_target=0.002,\n",
    "#     nB_global=50,\n",
    "#     nB_tile=50,\n",
    "#     step_size=2**14,\n",
    "#     tuning_min_idx=20\n",
    "# )\n",
    "# D = adastate.init_data(P, lei_obj, 0)\n",
    "fp = f\"./{name}/data_params.pkl\"\n",
    "# adastate.save(fp, (P, D))\n",
    "with open(fp, 'rb') as f:\n",
    "    P, D = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f826d317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint 4d_full/2084.pkl\n"
     ]
    }
   ],
   "source": [
    "load_iter = 'latest'\n",
    "S, load_iter, fn = adastate.load(name, load_iter)\n",
    "if S is None:\n",
    "    print('initializing')\n",
    "    S = adastate.init_state(P, g)\n",
    "S.todo[0] = True\n",
    "S.db.data = S.db.data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a390112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.276984224, 16.054652928)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    S.db.data.nbytes +\n",
    "    S.todo.nbytes + \n",
    "    S.sim_sizes.nbytes + \n",
    "    S.g.thetas.nbytes +\n",
    "    S.g.radii.nbytes + \n",
    "    S.g.null_truth.nbytes +\n",
    "    S.g.grid_pt_idx.nbytes +\n",
    "    D.unifs.nbytes + \n",
    "    sum([v.nbytes for v in D.bootstrap_idxs.values()]) + \n",
    "    sum([t.nbytes for t in lei_obj.pd_table.tables]) + \n",
    "    sum([t.nbytes for t in lei_obj.pr_best_pps_1_table.tables]) +\n",
    "    sum([t.nbytes for t in lei_obj.pps_2_table.tables])\n",
    ") / 1e9, psutil.Process(os.getpid()).memory_info().rss / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168abda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4d_full/storage_0.06375528470923503.pkl', 'rb') as f:\n",
    "    S_load = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c4566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8659/3676984174.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ), dtype=np.bool),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19215962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep_thresh = 0.075\n",
    "# keep1 = S.twb_min_lam < keep_thresh\n",
    "# keep2 = S_load.twb_min_lam < keep_thresh\n",
    "\n",
    "# S_store = adastate.AdaState(\n",
    "#     grid.concat_grids(grid.index_grid(S.g, ~keep1), grid.index_grid(S_load.g, ~keep2)),\n",
    "#     np.concatenate((\n",
    "#         S.sim_sizes[~keep1],\n",
    "#         S_load.sim_sizes[~keep2]\n",
    "#     ), dtype=np.int32),\n",
    "#     np.concatenate((\n",
    "#         S.todo[~keep1],\n",
    "#         S_load.todo[~keep2]\n",
    "#     ), dtype=bool),\n",
    "#     adastate.TileDB(\n",
    "#         np.concatenate((\n",
    "#             S.db.data[~keep1],\n",
    "#             S_load.db.data[~keep2]\n",
    "#         ), dtype=np.float32),\n",
    "#         S.db.slices\n",
    "#     )\n",
    "# )\n",
    "# print(S_store.g.n_tiles)\n",
    "# adastate.save(f\"./{name}/storage_{keep_thresh}.pkl\", S_store)\n",
    "# del S_store\n",
    "# gc.collect()\n",
    "\n",
    "# print('keeping', np.sum(keep1) + np.sum(keep2))\n",
    "# S_keep = adastate.AdaState(\n",
    "#     grid.concat_grids(grid.index_grid(S.g, keep1), grid.index_grid(S_load.g, keep2)),\n",
    "#     np.concatenate((\n",
    "#         S.sim_sizes[keep1],\n",
    "#         S_load.sim_sizes[keep2]\n",
    "#     ), dtype=np.int32),\n",
    "#     np.concatenate((\n",
    "#         S.todo[keep1],\n",
    "#         S_load.todo[keep2]\n",
    "#     ), dtype=np.bool),\n",
    "#     adastate.TileDB(\n",
    "#         np.concatenate((\n",
    "#             S.db.data[keep1],\n",
    "#             S_load.db.data[keep2]\n",
    "#         ), dtype=np.float32),\n",
    "#         S.db.slices\n",
    "#     )\n",
    "# )\n",
    "# S = S_keep\n",
    "# S.todo[0] = True\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f4e842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting iteration 2085 with 19925 tiles to process\n",
      "runtime prediction: inf\n",
      "tuning for 2048 simulations with 3787 tiles and batch size (64, 1024)\n",
      "tuning for 4096 simulations with 3853 tiles and batch size (64, 1024)\n",
      "tuning for 8192 simulations with 5777 tiles and batch size (64, 1024)\n",
      "tuning for 16384 simulations with 3208 tiles and batch size (64, 1024)\n",
      "tuning for 32768 simulations with 766 tiles and batch size (64, 1024)\n",
      "tuning for 65536 simulations with 1104 tiles and batch size (64, 1024)\n",
      "tuning for 131072 simulations with 1414 tiles and batch size (64, 1024)\n",
      "tuning for 524288 simulations with 16 tiles and batch size (64, 1024)\n",
      "step took 211.85s\n",
      "checkpointing took 0.00s\n",
      "tuning for 524288 simulations with 1 tiles and batch size (1, 16384)\n",
      "criterion took 37.89s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'overall_lam'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.06309'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'lam_std'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.0076'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'grid_cost'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.00119'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'bias'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.00612'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'total_slack'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.00731'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n_tiles'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17377245</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n_refine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n_refine_impossible'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n_moresims'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16272</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'n_moresims_impossible'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min(twb_min_lam)'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.04999'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min(twb_mean_lam)'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.06531'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min(twb_max_lam)'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.06683'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'twb_min_lam &lt; min(twb_mean_lam)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4147856</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'twb_min_lam &lt; min(twb_max_lam)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7654102</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'max(twb_min_lam[dangerous])'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0.06363'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'overall priority'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">94</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min(B_lamss)'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.032007065</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'min(B_lamss) priority'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7970800</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'memory usage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'25353 MB'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'memory usage per tile'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1530 B'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'overall_lam'\u001b[0m: \u001b[32m'0.06309'\u001b[0m,\n",
       "    \u001b[32m'lam_std'\u001b[0m: \u001b[32m'0.0076'\u001b[0m,\n",
       "    \u001b[32m'grid_cost'\u001b[0m: \u001b[32m'0.00119'\u001b[0m,\n",
       "    \u001b[32m'bias'\u001b[0m: \u001b[32m'0.00612'\u001b[0m,\n",
       "    \u001b[32m'total_slack'\u001b[0m: \u001b[32m'0.00731'\u001b[0m,\n",
       "    \u001b[32m'n_tiles'\u001b[0m: \u001b[1;36m17377245\u001b[0m,\n",
       "    \u001b[32m'n_refine'\u001b[0m: \u001b[1;36m112\u001b[0m,\n",
       "    \u001b[32m'n_refine_impossible'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'n_moresims'\u001b[0m: \u001b[1;36m16272\u001b[0m,\n",
       "    \u001b[32m'n_moresims_impossible'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'min\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtwb_min_lam\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[32m'0.04999'\u001b[0m,\n",
       "    \u001b[32m'min\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtwb_mean_lam\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[32m'0.06531'\u001b[0m,\n",
       "    \u001b[32m'min\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtwb_max_lam\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[32m'0.06683'\u001b[0m,\n",
       "    \u001b[32m'twb_min_lam < min\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtwb_mean_lam\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m4147856\u001b[0m,\n",
       "    \u001b[32m'twb_min_lam < min\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtwb_max_lam\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m7654102\u001b[0m,\n",
       "    \u001b[32m'max\u001b[0m\u001b[32m(\u001b[0m\u001b[32mtwb_min_lam\u001b[0m\u001b[32m[\u001b[0m\u001b[32mdangerous\u001b[0m\u001b[32m]\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[32m'0.06363'\u001b[0m,\n",
       "    \u001b[32m'overall priority'\u001b[0m: \u001b[1;36m94\u001b[0m,\n",
       "    \u001b[32m'min\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB_lamss\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m0.032007065\u001b[0m,\n",
       "    \u001b[32m'min\u001b[0m\u001b[32m(\u001b[0m\u001b[32mB_lamss\u001b[0m\u001b[32m)\u001b[0m\u001b[32m priority'\u001b[0m: \u001b[1;36m7970800\u001b[0m,\n",
       "    \u001b[32m'memory usage'\u001b[0m: \u001b[32m'25353 MB'\u001b[0m,\n",
       "    \u001b[32m'memory usage per tile'\u001b[0m: \u001b[32m'1530 B'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refinement took 16.37s\n",
      "starting iteration 2086 with 18704 tiles to process\n",
      "runtime prediction: 235.94\n",
      "tuning for 2048 simulations with 2432 tiles and batch size (64, 1024)\n",
      "tuning for 4096 simulations with 6492 tiles and batch size (64, 1024)\n",
      "tuning for 8192 simulations with 1983 tiles and batch size (64, 1024)\n",
      "tuning for 16384 simulations with 1728 tiles and batch size (64, 1024)\n",
      "tuning for 32768 simulations with 3248 tiles and batch size (64, 1024)\n",
      "keyboard interrupt, checkpointing before exiting\n",
      "exiting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mruntime prediction: \u001b[39m\u001b[39m{\u001b[39;00mpredicted_time\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 18\u001b[0m R\u001b[39m.\u001b[39;49mstep(P, S, D)\n\u001b[1;32m     19\u001b[0m cost_per_sim \u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start) \u001b[39m/\u001b[39m total_effort\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep took \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/research/adagrid/adastate.py:256\u001b[0m, in \u001b[0;36mAdaRunner.step\u001b[0;34m(self, P, S, D)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, P, S, D):\n\u001b[1;32m    249\u001b[0m     S\u001b[39m.\u001b[39malpha0[S\u001b[39m.\u001b[39mtodo] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatched_invert_bound(\n\u001b[1;32m    250\u001b[0m         P\u001b[39m.\u001b[39malpha_target,\n\u001b[1;32m    251\u001b[0m         S\u001b[39m.\u001b[39mg\u001b[39m.\u001b[39mtheta_tiles[S\u001b[39m.\u001b[39mtodo],\n\u001b[1;32m    252\u001b[0m         S\u001b[39m.\u001b[39mg\u001b[39m.\u001b[39mvertices(S\u001b[39m.\u001b[39mtodo),\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_arm_samples,\n\u001b[1;32m    254\u001b[0m     )\n\u001b[0;32m--> 256\u001b[0m     bootstrap_cvs_todo \u001b[39m=\u001b[39m lts\u001b[39m.\u001b[39;49mbootstrap_tune_runner(\n\u001b[1;32m    257\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlei_obj,\n\u001b[1;32m    258\u001b[0m         S\u001b[39m.\u001b[39;49msim_sizes[S\u001b[39m.\u001b[39;49mtodo],\n\u001b[1;32m    259\u001b[0m         S\u001b[39m.\u001b[39;49malpha0[S\u001b[39m.\u001b[39;49mtodo],\n\u001b[1;32m    260\u001b[0m         S\u001b[39m.\u001b[39;49mg\u001b[39m.\u001b[39;49mtheta_tiles[S\u001b[39m.\u001b[39;49mtodo],\n\u001b[1;32m    261\u001b[0m         S\u001b[39m.\u001b[39;49mg\u001b[39m.\u001b[39;49mnull_truth[S\u001b[39m.\u001b[39;49mtodo],\n\u001b[1;32m    262\u001b[0m         D\u001b[39m.\u001b[39;49munifs,\n\u001b[1;32m    263\u001b[0m         D\u001b[39m.\u001b[39;49mbootstrap_idxs,\n\u001b[1;32m    264\u001b[0m         D\u001b[39m.\u001b[39;49munifs_order,\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    267\u001b[0m     S\u001b[39m.\u001b[39morig_lam[S\u001b[39m.\u001b[39mtodo] \u001b[39m=\u001b[39m bootstrap_cvs_todo[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m    268\u001b[0m     S\u001b[39m.\u001b[39mB_lam[S\u001b[39m.\u001b[39mtodo] \u001b[39m=\u001b[39m bootstrap_cvs_todo[:, \u001b[39m1\u001b[39m : \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m P\u001b[39m.\u001b[39mnB_global]\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/mini_imprint/lewis_drivers.py:171\u001b[0m, in \u001b[0;36mbootstrap_tune_runner\u001b[0;34m(lei_obj, sim_sizes, alpha, theta, null_truth, unifs, bootstrap_idxs, unifs_order, sim_batch_size, grid_batch_size)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m# TODO: avoid the unifs copy.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m unifs_chunk \u001b[39m=\u001b[39m unifs[:size]\n\u001b[0;32m--> 171\u001b[0m stats \u001b[39m=\u001b[39m batched_statv(\n\u001b[1;32m    172\u001b[0m     lei_obj, theta[idx], null_truth[idx], unifs_chunk, unifs_order\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[39mdel\u001b[39;00m unifs_chunk\n\u001b[1;32m    175\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/lewislib/batch.py:159\u001b[0m, in \u001b[0;36mbatch.<locals>.internal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minternal\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 159\u001b[0m     outs, n_pad \u001b[39m=\u001b[39m f_batch_all(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    161\u001b[0m     return_first \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outs[\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39mndarray) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(outs[\u001b[39m0\u001b[39m], jnp\u001b[39m.\u001b[39mDeviceArray):\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/lewislib/batch.py:128\u001b[0m, in \u001b[0;36mbatch_all.<locals>.internal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minternal\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 128\u001b[0m     outs \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(out \u001b[39mfor\u001b[39;49;00m out \u001b[39min\u001b[39;49;00m f_batch(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m outs), outs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/lewislib/batch.py:128\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minternal\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 128\u001b[0m     outs \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(out \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m f_batch(\u001b[39m*\u001b[39margs))\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m outs), outs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/lewislib/batch.py:95\u001b[0m, in \u001b[0;36mbatch_yield.<locals>.internal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_full_batches):\n\u001b[1;32m     89\u001b[0m     batched_args \u001b[39m=\u001b[39m _create_batched_args(\n\u001b[1;32m     90\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m     91\u001b[0m         in_axes\u001b[39m=\u001b[39min_axes,\n\u001b[1;32m     92\u001b[0m         start\u001b[39m=\u001b[39mstart,\n\u001b[1;32m     93\u001b[0m         end\u001b[39m=\u001b[39mend,\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m     \u001b[39myield\u001b[39;00m (f(\u001b[39m*\u001b[39;49mbatched_args), \u001b[39m0\u001b[39m)\n\u001b[1;32m     96\u001b[0m     start \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_size\n\u001b[1;32m     97\u001b[0m     end \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_size\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/lewislib/batch.py:159\u001b[0m, in \u001b[0;36mbatch.<locals>.internal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minternal\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 159\u001b[0m     outs, n_pad \u001b[39m=\u001b[39m f_batch_all(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    161\u001b[0m     return_first \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outs[\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39mndarray) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(outs[\u001b[39m0\u001b[39m], jnp\u001b[39m.\u001b[39mDeviceArray):\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/lewislib/batch.py:128\u001b[0m, in \u001b[0;36mbatch_all.<locals>.internal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minternal\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 128\u001b[0m     outs \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(out \u001b[39mfor\u001b[39;49;00m out \u001b[39min\u001b[39;49;00m f_batch(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m outs), outs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/lewislib/batch.py:128\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minternal\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 128\u001b[0m     outs \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(out \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m f_batch(\u001b[39m*\u001b[39margs))\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m outs), outs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/confirmasaurus/confirm/confirm/lewislib/batch.py:95\u001b[0m, in \u001b[0;36mbatch_yield.<locals>.internal\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_full_batches):\n\u001b[1;32m     89\u001b[0m     batched_args \u001b[39m=\u001b[39m _create_batched_args(\n\u001b[1;32m     90\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m     91\u001b[0m         in_axes\u001b[39m=\u001b[39min_axes,\n\u001b[1;32m     92\u001b[0m         start\u001b[39m=\u001b[39mstart,\n\u001b[1;32m     93\u001b[0m         end\u001b[39m=\u001b[39mend,\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m     \u001b[39myield\u001b[39;00m (f(\u001b[39m*\u001b[39;49mbatched_args), \u001b[39m0\u001b[39m)\n\u001b[1;32m     96\u001b[0m     start \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_size\n\u001b[1;32m     97\u001b[0m     end \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_size\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# assign the first tile todo so that we have something to do!\n",
    "S.todo[0]=True\n",
    "\n",
    "R = adastate.AdaRunner(P, lei_obj)\n",
    "iter_max = 10000\n",
    "cost_per_sim = np.inf\n",
    "try:\n",
    "    for II in range(load_iter + 1, iter_max):\n",
    "        if np.sum(S.todo) == 0:\n",
    "            break\n",
    "\n",
    "        print(f\"starting iteration {II} with {np.sum(S.todo)} tiles to process\")\n",
    "        total_effort = np.sum(S.sim_sizes[S.todo])\n",
    "        predicted_time = total_effort * cost_per_sim\n",
    "        print(f\"runtime prediction: {predicted_time:.2f}\")\n",
    "\n",
    "        start = time.time()\n",
    "        R.step(P, S, D)\n",
    "        cost_per_sim = (time.time() - start) / total_effort\n",
    "        print(f\"step took {time.time() - start:.2f}s\")\n",
    "\n",
    "        start = time.time()\n",
    "        if II % 10 == 0:\n",
    "            adastate.save(f\"{name}/{II}.pkl\", S)\n",
    "            for old_i in checkpoint.exponential_delete(II, base=1):\n",
    "                fp = f\"{name}/{old_i}.pkl\"\n",
    "                if os.path.exists(fp):\n",
    "                    os.remove(fp)\n",
    "        print(f\"checkpointing took {time.time() - start:.2f}s\")\n",
    "\n",
    "        start = time.time()\n",
    "        cr = Criterion(lei_obj, P, S, D)\n",
    "        print(f'criterion took {time.time() - start:.2f}s')\n",
    "        which_refine = cr.which_refine\n",
    "        which_deepen = cr.which_deepen\n",
    "        report = cr.report\n",
    "        del cr\n",
    "        gc.collect()\n",
    "        memory_usage = psutil.Process(os.getpid()).memory_info().rss\n",
    "        report['memory usage'] = f'{int(memory_usage / 1024 ** 2)} MB'\n",
    "        report['memory usage per tile'] = f'{memory_usage / S.g.n_tiles:.0f} B'\n",
    "        rprint(report)\n",
    "\n",
    "        start = time.time()\n",
    "        S.todo[:] = False\n",
    "        if (np.sum(which_refine) > 0 or np.sum(which_deepen) > 0) and II != iter_max - 1:\n",
    "            S.sim_sizes[which_deepen] = S.sim_sizes[which_deepen] * 2\n",
    "            S.todo[which_deepen] = True\n",
    "\n",
    "            S = S.refine(P, which_refine, null_hypos, symmetry)\n",
    "            gc.collect()\n",
    "            print(f\"refinement took {time.time() - start:.2f}s\")\n",
    "except:\n",
    "    # TODO: this might fail if the exception occurs during the refinement phase.\n",
    "    print('keyboard interrupt, checkpointing before exiting')\n",
    "    adastate.save(f\"{name}/{II}_exception.pkl\", S)\n",
    "    print('exiting')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572096ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
